{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "2eef04db",
        "3c1f26a6",
        "ab80ce06",
        "faa11481",
        "03c7f2aa"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemkumar247/Bajaj-HackRx/blob/main/BajajRAG_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u4rD96Bhomu",
        "outputId": "0eb05865-b029-4877-cee8-4fd9caf05cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Installing Core Libraries ---\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-astradb 0.6.0 requires numpy<2.0.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "langchain-community 0.3.27 requires numpy>=1.26.2; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.12.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.90 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCore Libraries installed successfully.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "#\n",
        "#  Complete RAG Implementation in Google Colab with Astra DB\n",
        "#\n",
        "#  This notebook walks you through the entire process of building a\n",
        "#  Retrieval-Augmented Generation (RAG) system using Astra DB as the\n",
        "#  cloud-based vector store.\n",
        "#\n",
        "# ==============================================================================\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 1: INSTALL CORE LIBRARIES (NUMPY and SENTENCE-TRANSFORMERS)\n",
        "# ==============================================================================\n",
        "# We install numpy with a specific version known to be compatible with\n",
        "# sentence-transformers, and then install sentence-transformers itself.\n",
        "# This helps mitigate potential dependency conflicts.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 1: Installing Core Libraries ---\")\n",
        "!pip install -q --upgrade numpy==1.23.5 sentence-transformers\n",
        "print(\"Core Libraries installed successfully.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb39cb13",
        "outputId": "395640c1-06ec-414b-b9e5-5df50605bec6"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 1.1: INSTALL REMAINING LIBRARIES\n",
        "# ==============================================================================\n",
        "# We install the rest of the necessary packages for our RAG pipeline.\n",
        "# - langchain: The core framework for building LLM applications.\n",
        "# - langchain-google-genai: For integrating with Google's Generative AI models.\n",
        "# - astrapy & langchain-astradb: For connecting to and using Astra DB.\n",
        "# - pypdf: For loading and reading PDF documents.\n",
        "# - langchain-community: For various community-contributed components, including document loaders.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 1.1: Installing Remaining Libraries ---\")\n",
        "!pip install -q --upgrade langchain langchain-google-genai \"astrapy>=0.7.0\" \"langchain-astradb>=0.1.0\" pypdf langchain-community\n",
        "print(\"Remaining Libraries installed successfully.\\n\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1.1: Installing Remaining Libraries ---\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRemaining Libraries installed successfully.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7af3a654",
        "outputId": "6cad17a5-8ae3-4693-8b27-38f81c6ecfb7"
      },
      "source": [
        "print(\"Attempting to reinstall sentence-transformers...\")\n",
        "!pip install -q sentence-transformers\n",
        "print(\"sentence-transformers installation attempt complete.\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to reinstall sentence-transformers...\n",
            "sentence-transformers installation attempt complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAHSS7JBnUjR",
        "outputId": "51fef5c4-dd19-4bcd-d2d7-0172c863096c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"--- Step 2: Setting up API Keys and Google Drive ---\")\n",
        "\n",
        "try:\n",
        "    # Load Google API Key\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"✅ Google API Key loaded successfully.\")\n",
        "    # Load Astra DB Credentials\n",
        "    os.environ['ASTRA_DB_API_ENDPOINT'] = userdata.get('ASTRA_DB_API_ENDPOINT')\n",
        "    os.environ['ASTRA_DB_APPLICATION_TOKEN'] = userdata.get('ASTRA_DB_APPLICATION_TOKEN')\n",
        "    print(\"✅ Astra DB credentials loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not load secrets. Please make sure you have set them correctly in Colab's secrets manager. Details: {e}\")\n",
        "\n",
        "# Mount Google Drive to access our files\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✅ Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not mount Google Drive: {e}\")\n",
        "print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4f9aSe1mBbh",
        "outputId": "350fc00e-0708-4568-ee2d-4f84310c59b0"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 2: Setting up API Keys and Google Drive ---\n",
            "✅ Google API Key loaded successfully.\n",
            "✅ Astra DB credentials loaded successfully.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Drive mounted successfully.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 3: LOAD THE DOCUMENT\n",
        "# ==============================================================================\n",
        "# We'll load a PDF document from our Google Drive.\n",
        "#\n",
        "# ACTION REQUIRED:\n",
        "# 1. Create a folder named 'RAG_Project' in your Google Drive.\n",
        "# 2. Upload a PDF document you want to use into this folder.\n",
        "# 3. Update the 'pdf_file_path' variable below with the name of your PDF file.\n",
        "# ==============================================================================\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "print(\"--- Step 3: Loading Document ---\")\n",
        "\n",
        "# UPDATE THIS PATH to point to your PDF file in Google Drive\n",
        "pdf_file_path = \"/content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\" # <-- CHANGE THIS\n",
        "\n",
        "if not os.path.exists(pdf_file_path):\n",
        "    print(f\"ERROR: The file was not found at '{pdf_file_path}'. Please check the path and file name.\")\n",
        "else:\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    documents = loader.load()\n",
        "    print(f\"Successfully loaded {len(documents)} pages from the document.\")\n",
        "    # Display a snippet from the first page\n",
        "    print(\"\\n--- Document Snippet ---\")\n",
        "    print(documents[0].page_content[:500])\n",
        "    print(\"------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8clvvzVn4Wr",
        "outputId": "6022e0b7-4b2d-453b-e624-d0f3646ec83c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 3: Loading Document ---\n",
            "Successfully loaded 49 pages from the document.\n",
            "\n",
            "--- Document Snippet ---\n",
            "UIN- BAJHLIP23020V012223                                 Global Health Care/ Policy Wordings/Page 1 \n",
            " \n",
            " \n",
            "Bajaj Allianz General Insurance Co. Ltd.                       \n",
            "Bajaj Allianz House, Airport Road, Yerawada, Pune - 411 006. Reg. No.: 113 \n",
            "For more details, log on to: www.bajajallianz.com | E-mail: bagichelp@bajajallianz.co.in or \n",
            "Call at: Sales - 1800 209 0144 / Service - 1800 209 5858 (Toll Free No.) \n",
            "Issuing Office: \n",
            " \n",
            "GLOBAL HEALTH CARE \n",
            " \n",
            " \n",
            "Policy Wordings \n",
            " \n",
            "UIN- BAJHLIP23020V012223 \n",
            "\n",
            "------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3b1dac3",
        "outputId": "79c31ff3-b7db-4813-e208-8d28cbef7a8f"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 3: LOAD MULTIPLE DOCUMENTS\n",
        "# ==============================================================================\n",
        "# We'll load multiple PDF documents from our Google Drive.\n",
        "#\n",
        "# ACTION REQUIRED:\n",
        "# 1. Update the 'pdf_file_paths' list below with the paths to ALL your PDF files.\n",
        "#    Make sure these paths start with '/content/drive/MyDrive/' and point to the\n",
        "#    exact location of each PDF file in your Google Drive.\n",
        "# ==============================================================================\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "print(\"--- Step 3: Loading Documents ---\")\n",
        "\n",
        "# UPDATE THIS LIST with the paths to all your PDF files in Google Drive\n",
        "pdf_file_paths = [\n",
        "    \"/content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\",\n",
        "    \"/content/drive/MyDrive/RAG_Project/Bajaj doc 2.pdf\",\n",
        "    \"/content/drive/MyDrive/RAG_Project/Bajaj doc 3.pdf\",\n",
        "    \"/content/drive/MyDrive/RAG_Project/Bajaj doc 4.pdf\",\n",
        "    \"/content/drive/MyDrive/RAG_Project/Bajaj doc 5.pdf\",\n",
        "    # Add more file paths here as needed\n",
        "]\n",
        "\n",
        "documents = []\n",
        "for file_path in pdf_file_paths:\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"ERROR: The file was not found at '{file_path}'. Skipping this file.\")\n",
        "        continue # Skip to the next file if the current one is not found\n",
        "    try:\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        loaded_docs = loader.load()\n",
        "        documents.extend(loaded_docs)\n",
        "        print(f\"Successfully loaded {len(loaded_docs)} pages from '{file_path}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Could not load file '{file_path}': {e}\")\n",
        "\n",
        "\n",
        "if documents:\n",
        "    print(f\"\\nSuccessfully loaded a total of {len(documents)} pages from all documents.\")\n",
        "    # Display a snippet from the first page of the first document\n",
        "    print(\"\\n--- Document Snippet ---\")\n",
        "    # Find the first document with content to display a snippet\n",
        "    first_doc_with_content = next((doc for doc in documents if doc.page_content), None)\n",
        "    if first_doc_with_content:\n",
        "        print(first_doc_with_content.page_content[:500])\n",
        "        print(\"------------------------\\n\")\n",
        "    else:\n",
        "        print(\"No document content found to display snippet.\")\n",
        "else:\n",
        "    print(\"No documents were loaded successfully. Please check the file paths.\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 3: Loading Documents ---\n",
            "Successfully loaded 49 pages from '/content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf'.\n",
            "Successfully loaded 101 pages from '/content/drive/MyDrive/RAG_Project/Bajaj doc 2.pdf'.\n",
            "Successfully loaded 2 pages from '/content/drive/MyDrive/RAG_Project/Bajaj doc 3.pdf'.\n",
            "Successfully loaded 39 pages from '/content/drive/MyDrive/RAG_Project/Bajaj doc 4.pdf'.\n",
            "Successfully loaded 31 pages from '/content/drive/MyDrive/RAG_Project/Bajaj doc 5.pdf'.\n",
            "\n",
            "Successfully loaded a total of 222 pages from all documents.\n",
            "\n",
            "--- Document Snippet ---\n",
            "UIN- BAJHLIP23020V012223                                 Global Health Care/ Policy Wordings/Page 1 \n",
            " \n",
            " \n",
            "Bajaj Allianz General Insurance Co. Ltd.                       \n",
            "Bajaj Allianz House, Airport Road, Yerawada, Pune - 411 006. Reg. No.: 113 \n",
            "For more details, log on to: www.bajajallianz.com | E-mail: bagichelp@bajajallianz.co.in or \n",
            "Call at: Sales - 1800 209 0144 / Service - 1800 209 5858 (Toll Free No.) \n",
            "Issuing Office: \n",
            " \n",
            "GLOBAL HEALTH CARE \n",
            " \n",
            " \n",
            "Policy Wordings \n",
            " \n",
            "UIN- BAJHLIP23020V012223 \n",
            "\n",
            "------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 4: CHUNK THE DOCUMENT\n",
        "# ==============================================================================\n",
        "# LLMs have a limited context window, so we must break our document into\n",
        "# smaller, meaningful chunks. This allows the model to process them.\n",
        "# ==============================================================================\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "print(\"--- Step 4: Chunking the Document ---\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # The size of each chunk in characters\n",
        "    chunk_overlap=200, # The number of characters to overlap between chunks\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Document split into {len(chunks)} chunks.\")\n",
        "# Display a sample chunk\n",
        "print(\"\\n--- Sample Chunk ---\")\n",
        "print(chunks[0].page_content)\n",
        "print(\"--------------------\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWRWNAFGqoYF",
        "outputId": "25b7b670-8bec-4100-b6d2-f3652fc91f8d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 4: Chunking the Document ---\n",
            "Document split into 1076 chunks.\n",
            "\n",
            "--- Sample Chunk ---\n",
            "UIN- BAJHLIP23020V012223                                 Global Health Care/ Policy Wordings/Page 1 \n",
            " \n",
            " \n",
            "Bajaj Allianz General Insurance Co. Ltd.                       \n",
            "Bajaj Allianz House, Airport Road, Yerawada, Pune - 411 006. Reg. No.: 113 \n",
            "For more details, log on to: www.bajajallianz.com | E-mail: bagichelp@bajajallianz.co.in or \n",
            "Call at: Sales - 1800 209 0144 / Service - 1800 209 5858 (Toll Free No.) \n",
            "Issuing Office: \n",
            " \n",
            "GLOBAL HEALTH CARE \n",
            " \n",
            " \n",
            "Policy Wordings \n",
            " \n",
            "UIN- BAJHLIP23020V012223 \n",
            "SECTION A) PREAMBLE \n",
            " \n",
            "Whereas the Insured described in the Policy Schedule hereto (hereinafter called the ‘Insured’  or “Policyholder” or \n",
            "“Insured Person”) has made to Bajaj Allianz General Insurance Company Limited (hereinafter called the “Company” \n",
            "or “Insurer” or “Insurance Company”) a proposal or Proposal as mentioned in the transcript of the Proposal, which \n",
            "shall be the basis of this Contract and is deemed to be incorporated herein, containing certain undertakings ,\n",
            "--------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 5: CREATE EMBEDDINGS AND VECTOR STORE IN ASTRA DB\n",
        "# ==============================================================================\n",
        "# We convert each chunk into a vector and store it in Astra DB.\n",
        "# This creates a persistent, scalable, and searchable memory for our documents.\n",
        "#\n",
        "# NOTE: Switching from HuggingFaceEmbeddings (sentence-transformers) to\n",
        "# GoogleGenerativeAIEmbeddings to resolve dependency conflicts.\n",
        "# ==============================================================================\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings # Original import\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings # Using Google's embeddings\n",
        "from langchain_astradb import AstraDBVectorStore\n",
        "import os # Make sure os is imported for accessing environment variables\n",
        "\n",
        "print(\"--- Step 5: Creating Embeddings and Vector Store in Astra DB ---\")\n",
        "\n",
        "# Initialize the embedding model\n",
        "print(\"Initializing embedding model...\")\n",
        "# embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\") # Original model\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # Using Google's embedding model\n",
        "print(\"Embedding model initialized.\")\n",
        "\n",
        "# Initialize the Astra DB vector store\n",
        "print(\"\\nInitializing Astra DB vector store...\")\n",
        "# ACTION REQUIRED: Choose a name for your collection in Astra DB\n",
        "collection_name = \"my_rag_collection\" # <-- You can change this name\n",
        "\n",
        "vector_store = AstraDBVectorStore(\n",
        "    embedding=embedding_model,\n",
        "    collection_name=collection_name,\n",
        "    api_endpoint=os.environ['ASTRA_DB_API_ENDPOINT'],\n",
        "    token=os.environ['ASTRA_DB_APPLICATION_TOKEN'],\n",
        ")\n",
        "print(f\"Astra DB vector store initialized with collection '{collection_name}'.\")\n",
        "\n",
        "# Add the document chunks to the vector store\n",
        "print(\"\\nAdding documents to Astra DB... (This may take a moment)\")\n",
        "# Ensure 'chunks' variable is available from a previous cell's execution\n",
        "if 'chunks' in globals() and chunks:\n",
        "    vector_store.add_documents(chunks)\n",
        "    print(f\"{len(chunks)} document chunks added to Astra DB successfully.\\n\")\n",
        "elif 'documents' in globals() and documents:\n",
        "     # If chunks were not created, try adding the original documents (though chunking is recommended)\n",
        "    print(\"Warning: 'chunks' variable not found or empty. Attempting to add original 'documents'. Chunking is highly recommended for better RAG performance.\")\n",
        "    vector_store.add_documents(documents)\n",
        "    print(f\"{len(documents)} documents added to Astra DB successfully.\\n\")\n",
        "else:\n",
        "    print(\"ERROR: No documents or chunks found to add to the vector store. Please run previous steps to load and chunk documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEBLRoH9qvDd",
        "outputId": "316dc8dd-caa0-43a8-951a-620d7ed6ea60"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 5: Creating Embeddings and Vector Store in Astra DB ---\n",
            "Initializing embedding model...\n",
            "Embedding model initialized.\n",
            "\n",
            "Initializing Astra DB vector store...\n",
            "Astra DB vector store initialized with collection 'my_rag_collection'.\n",
            "\n",
            "Adding documents to Astra DB... (This may take a moment)\n",
            "1076 document chunks added to Astra DB successfully.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 6: BUILD THE RAG CHAIN\n",
        "# ==============================================================================\n",
        "# Now we assemble the final chain that connects our components:\n",
        "# 1. The Retriever (which gets documents from our Astra DB vector store).\n",
        "# 2. The LLM (Google's Gemini Pro model).\n",
        "# 3. A Prompt Template (to guide the LLM's response).\n",
        "# ==============================================================================\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "print(\"--- Step 6: Building the RAG Chain ---\")\n",
        "\n",
        "# Initialize the LLM\n",
        "# Changed model from \"gemini-pro\" to \"gemini-1.5-flash-latest\" to avoid NotFound error\n",
        "llm = GoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0.7)\n",
        "print(\"LLM (gemini-1.5-flash-latest) initialized.\")\n",
        "\n",
        "# Create a retriever from our vector store\n",
        "retriever = vector_store.as_retriever()\n",
        "print(\"Retriever created from Astra DB vector store.\")\n",
        "\n",
        "# Create a custom prompt template\n",
        "prompt_template = \"\"\"\n",
        "INSTRUCTIONS:\n",
        "You are a helpful assistant. Your task is to answer the user's question based *only* on the context provided below.\n",
        "If the context does not contain the information needed to answer the question, you must state: \"I do not have enough information in the provided document to answer this question.\"\n",
        "Do not make up information or use any external knowledge.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# Create the RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",  # \"stuff\" means all retrieved chunks are \"stuffed\" into the prompt\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True, # This is crucial to see which chunks were used\n",
        "    chain_type_kwargs={\"prompt\": PROMPT}\n",
        ")\n",
        "print(\"RAG chain created successfully.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9NHtFUwucbX",
        "outputId": "47bde753-39cf-4ea3-d66e-d1569fe95694"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 6: Building the RAG Chain ---\n",
            "LLM (gemini-1.5-flash-latest) initialized.\n",
            "Retriever created from Astra DB vector store.\n",
            "RAG chain created successfully.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d34f1f94",
        "outputId": "9349edd9-a9ee-4499-abcc-df02dc6858ab"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: ASK A QUESTION INTERACTIVELY\n",
        "# ==============================================================================\n",
        "# Now that the RAG chain is set up, we can ask questions about the documents.\n",
        "# The chain will retrieve relevant information and use the LLM to generate\n",
        "# an answer based on the retrieved context.\n",
        "# This version allows you to input your question directly and shows\n",
        "# only the generated answer and the first source document.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 7: Asking a Question Interactively ---\")\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Invoke the RAG chain with your query\n",
        "response = qa_chain.invoke(query)\n",
        "\n",
        "# Print the answer\n",
        "print(\"\\n--- Answer ---\")\n",
        "print(response['result'])\n",
        "\n",
        "# Display only the first source document\n",
        "print(\"\\n--- Primary Source Document ---\")\n",
        "if response['source_documents']:\n",
        "    first_doc = response['source_documents'][0]\n",
        "    print(f\"Document 1:\")\n",
        "    print(f\"  Source: {first_doc.metadata.get('source', 'N/A')}\")\n",
        "    print(f\"  Page: {first_doc.metadata.get('page', 'N/A')}\")\n",
        "    print(f\"  Content Snippet: {first_doc.page_content[:200]}...\") # Print first 200 chars\n",
        "    print(\"-\" * 20)\n",
        "    print(\"Note: The answer may have been synthesized from multiple source documents, but only the first is shown here.\")\n",
        "else:\n",
        "    print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "print(\"\\nTask completed. You can now run the cell again to ask another question.\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7: Asking a Question Interactively ---\n",
            "Please enter your question about the documents: My mother is 68 years old and needs cataract surgery. Her policy has a sum insured of 10 Lakhs. Is this covered and are there any limits on the amount payable?\n",
            "\n",
            "--- Answer ---\n",
            "Yes, cataract surgery is covered.  For a 10 Lakh sum insured policy, the maximum payable amount is 25,000 per eye.\n",
            "\n",
            "--- Primary Source Document ---\n",
            "Document 1:\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 5.pdf\n",
            "  Page: 9\n",
            "  Content Snippet: Procedures/Medical Conditions/Ailments/Diseases\n",
            "Annual Sum Insured\n",
            ">20L\n",
            "Treatment of cataract Up to  25,000/ eye` Up to  50,000/ eye` Up to  75,000/ eye`\n",
            "Treatment of each and every ailment/procedure ...\n",
            "--------------------\n",
            "Note: The answer may have been synthesized from multiple source documents, but only the first is shown here.\n",
            "\n",
            "Task completed. You can now run the cell again to ask another question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45f47d3b"
      },
      "source": [
        "# Task\n",
        "Improve the accuracy of the program and format the output in a more clean and simple way that can be easily understood by a normal user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59cebed8"
      },
      "source": [
        "## Refine document loading and chunking\n",
        "\n",
        "### Subtask:\n",
        "Review the document loading and chunking strategy to ensure chunks are meaningful and appropriately sized for the embedding model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb3f9f04"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to re-evaluate the chunking strategy based on the document type and potentially adjust the `chunk_size` and `chunk_overlap` to create more meaningful chunks. I will then inspect sample chunks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20a9c83a",
        "outputId": "8c08e882-7a52-4060-adf3-20777c58ec2f"
      },
      "source": [
        "# Re-examine and potentially adjust chunking strategy\n",
        "\n",
        "print(\"--- Step 4: Re-examining Chunking Strategy ---\")\n",
        "\n",
        "# Define new chunking parameters\n",
        "new_chunk_size = 500  # Smaller chunk size\n",
        "new_chunk_overlap = 100 # Smaller overlap\n",
        "\n",
        "print(f\"Attempting to re-chunk documents with chunk_size={new_chunk_size} and chunk_overlap={new_chunk_overlap}\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=new_chunk_size,\n",
        "    chunk_overlap=new_chunk_overlap,\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Document split into {len(chunks)} chunks with new parameters.\")\n",
        "\n",
        "# Display several sample chunks for inspection\n",
        "print(\"\\n--- Sample Chunks for Inspection ---\")\n",
        "for i, chunk in enumerate(chunks[:3]): # Displaying the first 3 chunks\n",
        "    print(f\"--- Chunk {i+1} ---\")\n",
        "    print(chunk.page_content)\n",
        "    print(\"--------------------\\n\")\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 4: Re-examining Chunking Strategy ---\n",
            "Attempting to re-chunk documents with chunk_size=500 and chunk_overlap=100\n",
            "Document split into 2091 chunks with new parameters.\n",
            "\n",
            "--- Sample Chunks for Inspection ---\n",
            "--- Chunk 1 ---\n",
            "UIN- BAJHLIP23020V012223                                 Global Health Care/ Policy Wordings/Page 1 \n",
            " \n",
            " \n",
            "Bajaj Allianz General Insurance Co. Ltd.                       \n",
            "Bajaj Allianz House, Airport Road, Yerawada, Pune - 411 006. Reg. No.: 113 \n",
            "For more details, log on to: www.bajajallianz.com | E-mail: bagichelp@bajajallianz.co.in or \n",
            "Call at: Sales - 1800 209 0144 / Service - 1800 209 5858 (Toll Free No.) \n",
            "Issuing Office: \n",
            " \n",
            "GLOBAL HEALTH CARE \n",
            " \n",
            " \n",
            "Policy Wordings \n",
            " \n",
            "UIN- BAJHLIP23020V012223\n",
            "--------------------\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Issuing Office: \n",
            " \n",
            "GLOBAL HEALTH CARE \n",
            " \n",
            " \n",
            "Policy Wordings \n",
            " \n",
            "UIN- BAJHLIP23020V012223 \n",
            "SECTION A) PREAMBLE \n",
            " \n",
            "Whereas the Insured described in the Policy Schedule hereto (hereinafter called the ‘Insured’  or “Policyholder” or \n",
            "“Insured Person”) has made to Bajaj Allianz General Insurance Company Limited (hereinafter called the “Company” \n",
            "or “Insurer” or “Insurance Company”) a proposal or Proposal as mentioned in the transcript of the Proposal, which\n",
            "--------------------\n",
            "\n",
            "--- Chunk 3 ---\n",
            "shall be the basis of this Contract and is deemed to be incorporated herein, containing certain undertakings , \n",
            "declarations, information/particulars and statements, which is hereby agreed to be the basis of this Contract and be \n",
            "considered as incorporated herein, for the insurance Contract hereinafter contained and has paid the premium \n",
            "specified in the Policy Sche dule hereto as consideration for such insurance Contract, now the Company agrees,\n",
            "--------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "382384a4"
      },
      "source": [
        "## Optimize retrieval strategy\n",
        "\n",
        "### Subtask:\n",
        "Explore different retrieval methods (e.g., different similarity metrics, adding metadata filtering) beyond basic similarity search to fetch the most relevant chunks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d49ac7cb"
      },
      "source": [
        "**Reasoning**:\n",
        "I will start by examining the available metadata in the `chunks` to understand what I can use for filtering. Then, I will configure the retriever to use the \"mmr\" (Maximal Marginal Relevance) search type, which is a common alternative to the default similarity search, and also increase the number of retrieved documents by setting the `k` parameter to 5. This will allow the model to have more context to generate a better answer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11f5c480",
        "outputId": "31cc0796-8aea-48be-e837-e6a4000257cd"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 6.1: EXPLORE AND REFINE RETRIEVAL STRATEGY\n",
        "# ==============================================================================\n",
        "# We will enhance our retrieval process by:\n",
        "# 1. Inspecting the available metadata in our document chunks.\n",
        "# 2. Using a more advanced retrieval method, Maximal Marginal Relevance (MMR),\n",
        "#    to balance between relevance and diversity of the retrieved documents.\n",
        "# 3. Increasing the number of documents fetched to provide more context.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- Step 6.1: Exploring and Refining Retrieval Strategy ---\")\n",
        "\n",
        "# 1. Inspect metadata of a sample chunk\n",
        "if 'chunks' in globals() and chunks:\n",
        "    print(\"\\n--- Sample Chunk Metadata ---\")\n",
        "    sample_chunk_metadata = chunks[0].metadata\n",
        "    print(sample_chunk_metadata)\n",
        "    print(\"-----------------------------\\n\")\n",
        "else:\n",
        "    print(\"Warning: 'chunks' variable not found. Skipping metadata inspection.\")\n",
        "\n",
        "# 2. Re-configure the retriever to use MMR and fetch more documents\n",
        "print(\"Configuring retriever with Maximal Marginal Relevance (MMR)...\")\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"mmr\", # Use Maximal Marginal Relevance for retrieval\n",
        "    search_kwargs={'k': 5} # Fetch the top 5 most relevant documents\n",
        ")\n",
        "print(\"Retriever re-configured successfully with MMR and k=5.\\n\")\n",
        "\n",
        "# Re-create the RetrievalQA chain with the new retriever\n",
        "print(\"Re-building the RAG chain with the new retriever...\")\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": PROMPT}\n",
        ")\n",
        "print(\"RAG chain updated successfully.\\n\")\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 6.1: Exploring and Refining Retrieval Strategy ---\n",
            "\n",
            "--- Sample Chunk Metadata ---\n",
            "{'producer': 'Microsoft® Word 2016', 'creator': 'Microsoft® Word 2016', 'creationdate': '2022-06-16T20:06:13+05:30', 'author': 'Vinay Dhanokar/Head Office Pune/Corporate Communication/General', 'moddate': '2022-06-16T20:06:13+05:30', 'source': '/content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf', 'total_pages': 49, 'page': 0, 'page_label': '1'}\n",
            "-----------------------------\n",
            "\n",
            "Configuring retriever with Maximal Marginal Relevance (MMR)...\n",
            "Retriever re-configured successfully with MMR and k=5.\n",
            "\n",
            "Re-building the RAG chain with the new retriever...\n",
            "RAG chain updated successfully.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c986172"
      },
      "source": [
        "## Enhance prompt engineering\n",
        "\n",
        "### Subtask:\n",
        "Refine the prompt template used with the LLM to guide it towards generating more accurate and concise answers based on the retrieved context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8abb295"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the prompt template to be more specific about how the LLM should use the context and format the output, then update the RAG chain with the refined prompt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0810b631",
        "outputId": "90391230-68d0-43ba-c2a6-ba294311ac5e"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7.1: Refine the Prompt Template\n",
        "# ==============================================================================\n",
        "# We will update the prompt template to provide clearer instructions to the LLM\n",
        "# on how to utilize the context for generating accurate and user-friendly answers.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- Step 7.1: Refining the Prompt Template ---\")\n",
        "\n",
        "# Refine the prompt template\n",
        "prompt_template = \"\"\"\n",
        "INSTRUCTIONS:\n",
        "You are a helpful assistant specializing in analyzing insurance policy documents.\n",
        "Your task is to answer the user's question based *strictly* on the context provided below.\n",
        "Read the context carefully and synthesize the relevant information to provide a concise and accurate answer.\n",
        "If the answer is found, present it clearly and directly.\n",
        "If the context does NOT contain the information needed to answer the question, you MUST respond with: \"I do not have enough information in the provided document to answer this question.\"\n",
        "Do NOT make up information or use any external knowledge.\n",
        "Present your answer in a simple, easy-to-understand format, avoiding jargon where possible.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\"\n",
        "\n",
        "# Update the PROMPT variable with the refined template\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "print(\"Prompt template refined and updated.\")\n",
        "\n",
        "# Re-create the RetrievalQA chain with the updated PROMPT\n",
        "print(\"Re-building the RAG chain with the refined prompt...\")\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": PROMPT}\n",
        ")\n",
        "print(\"RAG chain updated successfully with the refined prompt.\\n\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7.1: Refining the Prompt Template ---\n",
            "Prompt template refined and updated.\n",
            "Re-building the RAG chain with the refined prompt...\n",
            "RAG chain updated successfully with the refined prompt.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "906288ba"
      },
      "source": [
        "## Improve output formatting\n",
        "\n",
        "### Subtask:\n",
        "Modify the final output presentation to be clearer and more easily understandable for a normal user, potentially using markdown formatting or structuring the answer differently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08c9ea13"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the interactive question answering code to improve the output formatting for better readability and user understanding, displaying multiple source documents if available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbbbc603",
        "outputId": "0ffebf67-6784-4e79-d24a-8ecc4fbcc83d"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: ASK A QUESTION INTERACTIVELY (Improved Output Formatting)\n",
        "# ==============================================================================\n",
        "# Now that the RAG chain is set up, we can ask questions about the documents.\n",
        "# The chain will retrieve relevant information and use the LLM to generate\n",
        "# an answer based on the retrieved context.\n",
        "# This version allows you to input your question directly and presents the\n",
        "# answer and source documents in a more user-friendly format.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 7: Asking a Question Interactively (Improved Output) ---\")\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Invoke the RAG chain with your query\n",
        "response = qa_chain.invoke(query)\n",
        "\n",
        "# Print the answer with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"✨ ANSWER ✨\")\n",
        "print(\"=\"*30)\n",
        "print(response['result'])\n",
        "\n",
        "# Display source documents with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"📚 SOURCE DOCUMENTS 📚\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "if response['source_documents']:\n",
        "    for i, doc in enumerate(response['source_documents']):\n",
        "        print(f\"\\n--- Document {i+1} ---\")\n",
        "        print(f\"  Source: {doc.metadata.get('source', 'N/A')}\")\n",
        "        print(f\"  Page: {doc.metadata.get('page', 'N/A')}\")\n",
        "        # Display a more substantial snippet, e.g., the full content or a larger portion\n",
        "        # For simplicity and to avoid overwhelming output, let's display the first 500 characters\n",
        "        # or the full content if shorter.\n",
        "        content_snippet = doc.page_content\n",
        "        if len(content_snippet) > 500:\n",
        "            content_snippet = content_snippet[:500] + \"...\"\n",
        "        print(f\"  Content Snippet:\\n{content_snippet}\")\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "print(\"\\nTask completed. You can now run the cell again to ask another question.\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7: Asking a Question Interactively (Improved Output) ---\n",
            "Please enter your question about the documents: I am a 32-year-old woman. My husband and I have been covered under the Easy Health Family plan for the last 3 years. Are the costs for a caesarean delivery covered?\n",
            "\n",
            "==============================\n",
            "✨ ANSWER ✨\n",
            "==============================\n",
            "I do not have enough information in the provided document to answer this question.  While the document details maternity coverage costs for caesarean deliveries under different plans, it does not specify whether the \"Easy Health Family plan\" corresponds to one of the listed options.\n",
            "\n",
            "==============================\n",
            "📚 SOURCE DOCUMENTS 📚\n",
            "==============================\n",
            "\n",
            "--- Document 1 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 4.pdf\n",
            "  Page: 34\n",
            "  Content Snippet:\n",
            "hospitalisation \n",
            "3 a) Maternity \n",
            "Expenses  \n",
            " \n",
            "Not Covered \n",
            "Normal \n",
            "Delivery Rs. \n",
            "15,000* \n",
            "Caesarean \n",
            "Delivery Rs. \n",
            "25,000* \n",
            "(* Including \n",
            "Pre/Post \n",
            "Natal limit of \n",
            "Rs.1,500 and \n",
            "New Born \n",
            "limit of \n",
            "Rs.2,000) \n",
            "[Waiting \n",
            "Period 4 \n",
            "years] \n",
            "Normal \n",
            "Delivery Rs. \n",
            "25,000* \n",
            "Caesarean \n",
            "Delivery Rs. \n",
            "40,000* \n",
            "(* Including \n",
            "Pre/Post \n",
            "Natal limit \n",
            "of Rs. 2,500 \n",
            "and New \n",
            "Born limit of \n",
            "Rs.3,500) \n",
            "[Waiting \n",
            "Period 4 \n",
            "years] \n",
            "  Normal Delivery Rs. \n",
            "30,000* \n",
            "Caesarean Delivery Rs. \n",
            "50,000* \n",
            "(* Including Pre/Po...\n",
            "--------------------\n",
            "\n",
            "--- Document 2 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 26\n",
            "  Content Snippet:\n",
            "in  Your Table of Benefits:  \n",
            " Dental treatment, dental surgery, periodontics, orthodontics and dental prostheses. The only exception is \n",
            "oral and maxillofacial surgical procedures, which are covered within the overall limit of  Your In-patient Plan \n",
            " Dietician fees \n",
            " Expenses for one person accompanying an evacuated/repatriated person \n",
            " Home delivery \n",
            " Infertility treatment  \n",
            " Laser eye treatment.  \n",
            " Out-patient treatment  \n",
            " Prescribed glasses and contact lenses including eye examinatio...\n",
            "--------------------\n",
            "\n",
            "--- Document 3 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 4.pdf\n",
            "  Page: 33\n",
            "  Content Snippet:\n",
            "HDFC ERGO General Insurance Company Limited \n",
            " \n",
            " \n",
            "HDFC ERGO General Insurance Company Limited. IRDAI Reg. No.146. CIN: U66030MH2007PLC177117. Registered & \n",
            "Corporate Office: 1st Floor, HDFC House, 165-166 Backbay Reclamation, H. T. Parekh Marg, Churchgate, Mumbai – 400 \n",
            "020. Trade Logo displayed above belongs to HDFC Ltd and ERGO International AG and used by the Company under \n",
            "license. Easy Health UIN: HDFHLIP23024V072223 \n",
            "  34 | P a g e                     \n",
            "accompanying \n",
            "an insured child \n",
            "Maximu...\n",
            "--------------------\n",
            "\n",
            "--- Document 4 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 22\n",
            "  Content Snippet:\n",
            "14) Expenses incurred because of complications directly caused by an Illness, Injury or treatment for which cover is \n",
            "excluded or limited under Your plan. \n",
            "15) Consultations performed and any drugs or treatments prescribed by You, Your spouse, parents or children. \n",
            "16) Dental veneers and related procedures, unless medically necessary. \n",
            "17) Costs in respect of a family therapist or counsellor for out-patient mental illness treatment. \n",
            "18) Doctor’s fees for the completion of a Claim Form or other ...\n",
            "--------------------\n",
            "\n",
            "--- Document 5 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 4.pdf\n",
            "  Page: 14\n",
            "  Content Snippet:\n",
            "applicable. \n",
            " \n",
            "Plan Standard Exclusive \n",
            "Easy Health Individual Upto 1% of Sum Insured per \n",
            "Insured Person upto Rs.5000, only \n",
            "once at the end of a block of every \n",
            "continuous four claim free years. \n",
            "Upto 1% of Sum Insured subject to a \n",
            "Maximum of Rs.5,000 per Insured Person, \n",
            "only once at the end of a block of every \n",
            "continuous three policy years \n",
            " \n",
            "Easy Health Family Upto 1% of Sum Insured per Policy \n",
            "upto Rs.5000, only once at the end \n",
            "of a block of every continuous four \n",
            "claim free years \n",
            " \n",
            "Up...\n",
            "--------------------\n",
            "\n",
            "Task completed. You can now run the cell again to ask another question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6df7ca1f"
      },
      "source": [
        "## Evaluate and iterate\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the current performance of the RAG system with the improved chunking, retrieval, and prompt. Test with a variety of questions and analyze the answers and source documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c412c8c9"
      },
      "source": [
        "**Reasoning**:\n",
        "Run the interactive question answering cell multiple times to evaluate the RAG system's performance with the updated chunking, retrieval, and prompt. I will manually analyze the responses and source documents for each question.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95627e92",
        "outputId": "c2084977-ed9e-4dc0-bbc2-d23d4fd8c708"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: ASK A QUESTION INTERACTIVELY (Improved Output Formatting)\n",
        "# ==============================================================================\n",
        "# Running the interactive question answering cell as instructed for evaluation.\n",
        "# I will ask a variety of questions and manually analyze the output.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 7: Asking a Question Interactively (Evaluation Run) ---\")\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Invoke the RAG chain with your query\n",
        "response = qa_chain.invoke(query)\n",
        "\n",
        "# Print the answer with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"✨ ANSWER ✨\")\n",
        "print(\"=\"*30)\n",
        "print(response['result'])\n",
        "\n",
        "# Display source documents with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"📚 SOURCE DOCUMENTS 📚\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "if response['source_documents']:\n",
        "    for i, doc in enumerate(response['source_documents']):\n",
        "        print(f\"\\n--- Document {i+1} ---\")\n",
        "        print(f\"  Source: {doc.metadata.get('source', 'N/A')}\")\n",
        "        print(f\"  Page: {doc.metadata.get('page', 'N/A')}\")\n",
        "        # Display a more substantial snippet, e.g., the full content or a larger portion\n",
        "        # For simplicity and to avoid overwhelming output, let's display the first 500 characters\n",
        "        # or the full content if shorter.\n",
        "        content_snippet = doc.page_content\n",
        "        if len(content_snippet) > 500:\n",
        "            content_snippet = content_snippet[:500] + \"...\"\n",
        "        print(f\"  Content Snippet:\\n{content_snippet}\")\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "print(\"\\nTask completed. Please analyze the output and re-run the cell to ask another question.\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7: Asking a Question Interactively (Evaluation Run) ---\n",
            "Please enter your question about the documents: A 55-year-old man was diagnosed with hypertension 5 years ago. He is now hospitalized for a cardiac condition. Is his hospitalization covered under the Golden Shield policy if the policy was taken 18 months ago?\n",
            "\n",
            "==============================\n",
            "✨ ANSWER ✨\n",
            "==============================\n",
            "I do not have enough information in the provided document to answer this question.\n",
            "\n",
            "==============================\n",
            "📚 SOURCE DOCUMENTS 📚\n",
            "==============================\n",
            "\n",
            "--- Document 1 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 5.pdf\n",
            "  Page: 6\n",
            "  Content Snippet:\n",
            "h)  Diabetes mellitus and insipidus;\n",
            " i)  Epilepsy;\n",
            " j)  Hypertension;\n",
            " k)  Pyrexia of any origin\n",
            "8.  Home Care Treatment\n",
            " We will cover the medical expenses incurred by the Insured \n",
            "person on home care treatment maximum up to 5% of \n",
            "Annual Sum Insured provided that :\n",
            " a.  The Medical Practitioner advices the Insured Person to \n",
            "undergo treatment at home\n",
            " b.  There is a continuous active line of treatment with \n",
            "monitoring of the health status by a medical \n",
            "practitioner for each day through the du...\n",
            "--------------------\n",
            "\n",
            "--- Document 2 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 5.pdf\n",
            "  Page: 5\n",
            "  Content Snippet:\n",
            "any of the following:\n",
            " i.  Pre-hospitalization Medical Expenses or Post-\n",
            "hospitalization Medical Expenses of the organ donor.\n",
            " ii.  Screening expenses of the organ donor.\n",
            " iii.  Any other Medical Expenses as a result of the \n",
            "harvesting from the organ donor.\n",
            " iv.  Costs directly or indirectly associated with the \n",
            "acquisition of the donor’s organ (other than \n",
            "hospitalisation costs involved).\n",
            " v.  Transplant of any organ/tissue where the transplant is \n",
            "experimental or investigational.\n",
            " vi.  Expense...\n",
            "--------------------\n",
            "\n",
            "--- Document 3 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 5.pdf\n",
            "  Page: 27\n",
            "  Content Snippet:\n",
            "Golden Shield\n",
            "28 CIN: L67200MH2000PLC129408UIN : ICIHLIP22012V012223\n",
            "Illustrations for claim settlement  (Contd.)\n",
            "Illustration 2 - Insured person opted for voluntary deductible (Contd.)\n",
            "Heading Particulars Scenario 1 Scenario 2 Scenario 3\n",
            "J. Sub-limit for cardiovascular diseases  ` 3,50,000  ` 3,50,000  ` 3,50,000\n",
            "Final payable amount to Insured Person [lesser amount out of I,J]  ` 35,000  ` 67,500K.\n",
            "Balance Annual Sum Insured [A-K]  ` 19,65,000  ` 19,32,500  ` 20,00,000L.\n",
            "*It has been assumed t...\n",
            "--------------------\n",
            "\n",
            "--- Document 4 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 5.pdf\n",
            "  Page: 28\n",
            "  Content Snippet:\n",
            "Golden Shield\n",
            "29 CIN: L67200MH2000PLC129408UIN : ICIHLIP22012V012223\n",
            "of Policy) OR communicate non admissibility of claim \n",
            "within 14 days after You submit complete set of \n",
            "documents & information in respect of the claims. In \n",
            "case We fail to make the payment of admissible claims \n",
            "or to communicate non admissibility of claim within the \n",
            "time period, We shall pay 2% interest over and above \n",
            "the rate defined as per IRDAI (Protection of \n",
            "Policyholder's interest) Regulation 2017.\n",
            " B. For Cashless Cla...\n",
            "--------------------\n",
            "\n",
            "--- Document 5 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 5.pdf\n",
            "  Page: 3\n",
            "  Content Snippet:\n",
            "Policy Schedule or any revisions thereof based on \n",
            "Claim settled under the Policy.\n",
            "  Break in Policy occurs at the end of the existing policy \n",
            "term, when the premium due for renewal on a given \n",
            "policy is not paid on or before the premium renewal \n",
            "date or within 30 days thereof.\n",
            "  Claim means a demand made by You or on Your behalf \n",
            "for payment of Medical Expenses or any other \n",
            "expenses or benefits, as covered under the Policy.\n",
            "  Immediate Family means spouse, dependent children, \n",
            "brother(s), sist...\n",
            "--------------------\n",
            "\n",
            "Task completed. Please analyze the output and re-run the cell to ask another question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0378b6e8"
      },
      "source": [
        "**Reasoning**:\n",
        "Continue running the interactive question answering cell to evaluate the RAG system's performance with different questions, analyzing the answers and source documents each time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3c8582a",
        "outputId": "c7159ccd-adf5-43f3-f635-a42417fc154a"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: ASK A QUESTION INTERACTIVELY (Improved Output Formatting)\n",
        "# ==============================================================================\n",
        "# Running the interactive question answering cell as instructed for evaluation.\n",
        "# I will ask a variety of questions and manually analyze the output.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 7: Asking a Question Interactively (Evaluation Run) ---\")\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Invoke the RAG chain with your query\n",
        "response = qa_chain.invoke(query)\n",
        "\n",
        "# Print the answer with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"✨ ANSWER ✨\")\n",
        "print(\"=\"*30)\n",
        "print(response['result'])\n",
        "\n",
        "# Display source documents with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"📚 SOURCE DOCUMENTS 📚\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "if response['source_documents']:\n",
        "    for i, doc in enumerate(response['source_documents']):\n",
        "        print(f\"\\n--- Document {i+1} ---\")\n",
        "        print(f\"  Source: {doc.metadata.get('source', 'N/A')}\")\n",
        "        print(f\"  Page: {doc.metadata.get('page', 'N/A')}\")\n",
        "        # Display a more substantial snippet, e.g., the full content or a larger portion\n",
        "        # For simplicity and to avoid overwhelming output, let's display the first 500 characters\n",
        "        # or the full content if shorter.\n",
        "        content_snippet = doc.page_content\n",
        "        if len(content_snippet) > 500:\n",
        "            content_snippet = content_snippet[:500] + \"...\"\n",
        "        print(f\"  Content Snippet:\\n{content_snippet}\")\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "print(\"\\nTask completed. Please analyze the output and re-run the cell to ask another question.\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7: Asking a Question Interactively (Evaluation Run) ---\n",
            "Please enter your question about the documents: My 25-year-old son broke his front tooth in a bike accident and needs urgent dental surgery. Is this covered under the Global Health Care policy?\n",
            "\n",
            "==============================\n",
            "✨ ANSWER ✨\n",
            "==============================\n",
            "Based on the provided text, emergency inpatient dental treatment arising from an accident is covered,  provided the treatment begins within 24 hours of the accident.  However, outpatient dental treatment is not covered.  Whether this specific case is inpatient or outpatient is not specified, therefore I do not have enough information in the provided document to answer this question.\n",
            "\n",
            "==============================\n",
            "📚 SOURCE DOCUMENTS 📚\n",
            "==============================\n",
            "\n",
            "--- Document 1 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 17\n",
            "  Content Snippet:\n",
            "treatment and dental prescription drugs. \n",
            " \n",
            "2. Dental surgery outside India \n",
            "We will pay Customary and Reasonable expenses up to the limits specified in the Policy Schedule incurred for \n",
            "Dental Surgery which includes the surgical extraction of teeth, as well as other tooth-related surgical procedures \n",
            "such as apicoectomy, Surgical removal of cysts, Orthognathic surgeries for the correction of malocclusion and\n",
            "--------------------\n",
            "\n",
            "--- Document 2 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 2.pdf\n",
            "  Page: 30\n",
            "  Content Snippet:\n",
            "cover-Personal Accident - Common Carrier for Accidental Death and Permanent Total Disability, if opted. \n",
            " \n",
            "Endorsement no.5 – DENTAL TREATMENT EXPENSES: \n",
            "a. Coverage \n",
            "The Policy shall reimburse to the Insured/Insured Person expenses incurred in respect of acute anesthetic treatment \n",
            "of a natural tooth or teeth during a trip as an Inpatient or as an out-patient arising from an accidental injury, but not \n",
            "exceeding the Sum Insured specified in the Policy Certificate. \n",
            "  \n",
            "b. Specific Exclusions App...\n",
            "--------------------\n",
            "\n",
            "--- Document 3 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 26\n",
            "  Content Snippet:\n",
            "in  Your Table of Benefits:  \n",
            " Dental treatment, dental surgery, periodontics, orthodontics and dental prostheses. The only exception is \n",
            "oral and maxillofacial surgical procedures, which are covered within the overall limit of  Your In-patient Plan \n",
            " Dietician fees \n",
            " Expenses for one person accompanying an evacuated/repatriated person \n",
            " Home delivery \n",
            " Infertility treatment  \n",
            " Laser eye treatment.  \n",
            " Out-patient treatment  \n",
            " Prescribed glasses and contact lenses including eye examinatio...\n",
            "--------------------\n",
            "\n",
            "--- Document 4 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 5\n",
            "  Content Snippet:\n",
            "presented symptoms. \n",
            " \n",
            "13. Emergency and Emergency Treatment \n",
            "Emergency Treatment shall be accordingly taken/interpreted as per definition of Emergency Care read with this \n",
            "definition. Provided however only treatment commencing within 24 hours of the Emergency event will be covered. \n",
            " \n",
            "14. Emergency Inpatient Dental Treatment arising from an Accident:- \n",
            "Emergency Inpatient Dental Treatment arising from an Accident refers to acute Emergency Dental Treatment that \n",
            "is due to a serious Accident and ...\n",
            "--------------------\n",
            "\n",
            "--- Document 5 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 27\n",
            "  Content Snippet:\n",
            "applied during subsequent renewals. \n",
            "b. Out-patient Dental Treatment expenses will not be covered. \n",
            " \n",
            "2. Alternate/Complementary Treatment \n",
            "During the first year of Global Health Care Policy with Us, 30 days waiting period would be applicable for all claims \n",
            "under Alternate/Complementary Treatment except those arising out of Accidental Injury, however the waiting \n",
            "period would not be applied during subsequent renewals. \n",
            " \n",
            "3. Physiotherapy Benefit \n",
            "a. During the first year of Global Health Care P...\n",
            "--------------------\n",
            "\n",
            "Task completed. Please analyze the output and re-run the cell to ask another question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24205b68"
      },
      "source": [
        "**Reasoning**:\n",
        "Continue running the interactive question answering cell to evaluate the RAG system's performance with different questions, analyzing the answers and source documents each time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24fa72fb",
        "outputId": "090e316f-22d7-4d7a-be53-c4d079d84157"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: ASK A QUESTION INTERACTIVELY (Improved Output Formatting)\n",
        "# ==============================================================================\n",
        "# Running the interactive question answering cell as instructed for evaluation.\n",
        "# I will ask a variety of questions and manually analyze the output.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 7: Asking a Question Interactively (Evaluation Run) ---\")\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Invoke the RAG chain with your query\n",
        "response = qa_chain.invoke(query)\n",
        "\n",
        "# Print the answer with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"✨ ANSWER ✨\")\n",
        "print(\"=\"*30)\n",
        "print(response['result'])\n",
        "\n",
        "# Display source documents with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"📚 SOURCE DOCUMENTS 📚\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "if response['source_documents']:\n",
        "    for i, doc in enumerate(response['source_documents']):\n",
        "        print(f\"\\n--- Document {i+1} ---\")\n",
        "        print(f\"  Source: {doc.metadata.get('source', 'N/A')}\")\n",
        "        print(f\"  Page: {doc.metadata.get('page', 'N/A')}\")\n",
        "        # Display a more substantial snippet, e.g., the full content or a larger portion\n",
        "        # For simplicity and to avoid overwhelming output, let's display the first 500 characters\n",
        "        # or the full content if shorter.\n",
        "        content_snippet = doc.page_content\n",
        "        if len(content_snippet) > 500:\n",
        "            content_snippet = content_snippet[:500] + \"...\"\n",
        "        print(f\"  Content Snippet:\\n{content_snippet}\")\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "print(\"\\nTask completed. Please analyze the output and re-run the cell to ask another question.\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7: Asking a Question Interactively (Evaluation Run) ---\n",
            "Please enter your question about the documents: I am a 28-year-old woman and I want to get a rhinoplasty (nose job) for cosmetic reasons. Will the Easy Health policy cover this?\n",
            "\n",
            "==============================\n",
            "✨ ANSWER ✨\n",
            "==============================\n",
            "I do not have enough information in the provided document to answer this question.\n",
            "\n",
            "==============================\n",
            "📚 SOURCE DOCUMENTS 📚\n",
            "==============================\n",
            "\n",
            "--- Document 1 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 2.pdf\n",
            "  Page: 32\n",
            "  Content Snippet:\n",
            "an insured event. \n",
            "3. Treatment relating to the removal of physical ﬂaws or anomalies (cosmetic treatment or plastic surgery \n",
            "in any form or manner unless medically required as part of treatment for accidents and burns). \n",
            "4. Expenses incurred in connection with rest or recuperation at a spa, health resort, sanatorium, \n",
            "convalescence home, rehabilitation measures, private duty nursing, respite care, domiciliary care, long- \n",
            "term nursing care, custodial care and treatment related alcoholism and dr...\n",
            "--------------------\n",
            "\n",
            "--- Document 2 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 20\n",
            "  Content Snippet:\n",
            "15. Uterine Prolapse 16. Stones in the urinary and biliary systems \n",
            "17. Surgery on ears/tonsils/ \n",
            "adenoids/ paranasal sinuses \n",
            "18. Surgery on all internal or external tumours/ cysts/ \n",
            "nodules/polyps of any kind including breast lumps \n",
            "with exception of Malignant tumor or growth \n",
            " 19. Diseases of gall bladder including cholecystitis \n",
            "20. Pancreatitis 21. All forms of Cirrhosis \n",
            "22. Gout and rheumatism 23. Tonsilitis \n",
            "24. Surgery for varicose veins and \n",
            "varicose ulcers 25. Chronic Kidney Disease \n",
            "...\n",
            "--------------------\n",
            "\n",
            "--- Document 3 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 4.pdf\n",
            "  Page: 15\n",
            "  Content Snippet:\n",
            "declared and accepted without a specific exclusion. \n",
            "e) If the Insured Person is continuously covered without any break as defined under the \n",
            "applicable norms on portability/migration stipulated by IRDAI, then waiting period  for the \n",
            "same would be reduced to the extent of prior coverage. \n",
            "f) List of specific diseases/procedures: - \n",
            " \n",
            "Sl. \n",
            "No. \n",
            "Organ / Organ \n",
            "System \n",
            "Illness/Diagnosis (irrespective of \n",
            "treatments medical or surgical) \n",
            "Surgeries/ procedure (irrespective of \n",
            "any illness / diagnosi...\n",
            "--------------------\n",
            "\n",
            "--- Document 4 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 4.pdf\n",
            "  Page: 1\n",
            "  Content Snippet:\n",
            "the surgery has to be confirmed by a specialist Medical Practitioner  \n",
            "  The following are excluded:  \n",
            " Angioplasty and / or Any other intra-arterial procedures \n",
            " Any Key-hole surgery or laser surgery \n",
            " \n",
            "iii) First Heart Attack of Specified Severity:\n",
            "--------------------\n",
            "\n",
            "--- Document 5 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 24\n",
            "  Content Snippet:\n",
            "c. The surgery/Procedure conducted should be supported by clinical protocols \n",
            "d. The member has to be 18 years of age or older and \n",
            "e. Body Mass Index (BMI); \n",
            "i. greater than or equal to 40 or \n",
            "ii. greater than or equal to 35 in conjunction with any of the following severe co-morbidities following failure \n",
            "of less invasive methods of weight loss: \n",
            "f. Obesity-related cardiomyopathy \n",
            "g. Coronary heart disease \n",
            "h. Severe Sleep Apnea \n",
            "i. Uncontrolled Type2 Diabetes \n",
            " \n",
            "7) Change-of-gender treatments ...\n",
            "--------------------\n",
            "\n",
            "Task completed. Please analyze the output and re-run the cell to ask another question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea8a4533"
      },
      "source": [
        "**Reasoning**:\n",
        "Continue running the interactive question answering cell to evaluate the RAG system's performance with different questions, analyzing the answers and source documents each time. This is the final manual evaluation step before summarizing findings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22087452",
        "outputId": "4d5c61c9-18fb-437e-8c8f-48c20b848c92"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: ASK A QUESTION INTERACTIVELY (Improved Output Formatting)\n",
        "# ==============================================================================\n",
        "# Running the interactive question answering cell as instructed for evaluation.\n",
        "# I will ask a variety of questions and manually analyze the output.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 7: Asking a Question Interactively (Evaluation Run) ---\")\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Invoke the RAG chain with your query\n",
        "response = qa_chain.invoke(query)\n",
        "\n",
        "# Print the answer with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"✨ ANSWER ✨\")\n",
        "print(\"=\"*30)\n",
        "print(response['result'])\n",
        "\n",
        "# Display source documents with clear formatting\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"📚 SOURCE DOCUMENTS 📚\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "if response['source_documents']:\n",
        "    for i, doc in enumerate(response['source_documents']):\n",
        "        print(f\"\\n--- Document {i+1} ---\")\n",
        "        print(f\"  Source: {doc.metadata.get('source', 'N/A')}\")\n",
        "        print(f\"  Page: {doc.metadata.get('page', 'N/A')}\")\n",
        "        # Display a more substantial snippet, e.g., the full content or a larger portion\n",
        "        # For simplicity and to avoid overwhelming output, let's display the first 500 characters\n",
        "        # or the full content if shorter.\n",
        "        content_snippet = doc.page_content\n",
        "        if len(content_snippet) > 500:\n",
        "            content_snippet = content_snippet[:500] + \"...\"\n",
        "        print(f\"  Content Snippet:\\n{content_snippet}\")\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "print(\"\\nTask completed. Please analyze the output and re-run the cell to ask another question.\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7: Asking a Question Interactively (Evaluation Run) ---\n",
            "Please enter your question about the documents: A 35-year-old individual needs in-patient treatment for severe depression. Does the Global Health Care policy cover hospitalization for mental illness?\n",
            "\n",
            "==============================\n",
            "✨ ANSWER ✨\n",
            "==============================\n",
            "The provided text states that inpatient treatment for mental illness is covered,  but excludes treatment related to alcoholism, drug or substance abuse, or any addictive condition.  It also excludes outpatient treatment and treatment at specialized educational facilities for autism spectrum disorder.\n",
            "\n",
            "==============================\n",
            "📚 SOURCE DOCUMENTS 📚\n",
            "==============================\n",
            "\n",
            "--- Document 1 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 14\n",
            "  Content Snippet:\n",
            "b. The Hospitalization is for Medically Necessary Treatment. \n",
            "c. All day-care or Inpatient admissions must include prescription medication related to the condition. \n",
            "d. The treatment should be taken in Mental Health Establishment either wholly or partly meant for the care of \n",
            "persons with mental Illness, where persons with mental Illness are admitted for treatment. \n",
            " \n",
            "Exclusions: Mental Illness Treatment does not cover: \n",
            "a. Any expenses for Mental Illness Treatment related to Alcoholism, drug or...\n",
            "--------------------\n",
            "\n",
            "--- Document 2 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 15\n",
            "  Content Snippet:\n",
            "not covered. \n",
            "e. Out-patient Treatment for Mental Illness \n",
            " \n",
            "This cover is subject to the Sum Insured, sub-limits, terms, conditions and definitions, exclusions contained or \n",
            "otherwise expressed in this Policy. \n",
            " \n",
            "10. Rehabilitation \n",
            "Rehabilitation is defined as a set of interventions designed to optimize functioning and reduce disability in \n",
            "individuals with health conditions in interaction with their environment. It aims to restore original form or function \n",
            "after an acute Illness, Injury or s...\n",
            "--------------------\n",
            "\n",
            "--- Document 3 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 2.pdf\n",
            "  Page: 2\n",
            "  Content Snippet:\n",
            "Medically Necessary Treatment means any treatment, tests, medication, sta y in Hospital or part of a stay \n",
            "in Hospital in relation to the Insured Person which: \n",
            "i. is required for the medical management of the Illness or Injury suffered by the Insured Person;\n",
            "--------------------\n",
            "\n",
            "--- Document 4 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 27\n",
            "  Content Snippet:\n",
            "d. For autism spectrum disorder, admissions, stays or day care treatment at specialised educational facilities \n",
            "are not covered. \n",
            "e. Out-patient Treatment for Mental Illness. \n",
            "33) Emergency treatment outside area of cover \n",
            "Cover is not provided for curative or follow-up non-Emergency treatment, even if You are deemed unable to \n",
            "travel to a country within Your geographical area of cover. Nor does it extend to charges relating to maternity, \n",
            "pregnancy, childbirth or any complications of pregnancy ...\n",
            "--------------------\n",
            "\n",
            "--- Document 5 ---\n",
            "  Source: /content/drive/MyDrive/RAG_Project/Bajaj doc 1.pdf\n",
            "  Page: 12\n",
            "  Content Snippet:\n",
            "I. IN-PATIENT BENEFITS FOR INTERNATIONAL COVER \n",
            " \n",
            "1. In-patient Hospitalization Treatment \n",
            "If You are advised Hospitalization by a Medical Practitioner as defined under Policy because of Illness or \n",
            "Accidental Bodily Injury sustained or contracted during the Policy Period, then We will pay You, Reasonable and \n",
            "Customary Medical Expenses incurred subject to \n",
            "i. Room rent and Boarding expenses up to a Single Private Air Conditioned Room \n",
            "ii. If admitted in ICU, the Company will pay up to actual IC...\n",
            "--------------------\n",
            "\n",
            "Task completed. Please analyze the output and re-run the cell to ask another question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e373684"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The document chunking strategy was refined using a smaller `chunk_size` of 500 and `chunk_overlap` of 100, resulting in 2091 smaller, more focused chunks.\n",
        "*   The retrieval strategy was updated to use Maximal Marginal Relevance (MMR) search with `k=5` to fetch the top 5 documents, balancing relevance and diversity.\n",
        "*   The prompt template for the LLM was refined with explicit instructions to use the provided context strictly, be concise, and handle unanswerable questions by stating \"I do not have enough information in the provided document to answer this question.\"\n",
        "*   The final output formatting was improved to present the answer and source documents clearly with separators, labels, source file, page number, and a content snippet for each retrieved document.\n",
        "*   Evaluation showed that the system accurately answers questions when relevant information is retrieved and the output formatting is clear.\n",
        "*   Evaluation also revealed that the retrieval process sometimes retrieves irrelevant chunks alongside relevant ones, even when the model correctly identifies that it cannot answer a question from the provided context.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Further refine the retrieval mechanism to improve precision and reduce the retrieval of irrelevant chunks, possibly through techniques like hybrid search or re-ranking.\n",
        "*   Investigate ways to prevent retrieval altogether when the query is clearly outside the scope of the document content.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57ebec97"
      },
      "source": [
        "# Task\n",
        "Refine the RAG model to improve accuracy and output clarity by optimizing document processing, exploring different embedding models and retrieval strategies (including hybrid search and re-ranking), enhancing prompt engineering, considering alternative LLMs, improving output formatting, and implementing out-of-scope query detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7203d2c7"
      },
      "source": [
        "## Evaluate and potentially change embedding model\n",
        "\n",
        "### Subtask:\n",
        "Consider if a different embedding model might provide better vector representations for your specific document type, leading to improved retrieval accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7e43a93"
      },
      "source": [
        "**Reasoning**:\n",
        "I will select two alternative embedding models to test: a popular open-source model from Hugging Face (`'BAAI/bge-large-en-v1.5'`) known for its strong performance on retrieval benchmarks, and a commercial model from Cohere (`'embed-english-v3.0'`) which often performs well on semantic search tasks. To use the Cohere model, I will first need to install the `langchain-cohere` library and set up the API key.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ad6a29",
        "outputId": "a260e46f-4a2e-4ff6-97ef-1b447c8e593b"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 8: EXPLORE ALTERNATIVE EMBEDDING MODELS\n",
        "# ==============================================================================\n",
        "# To potentially improve retrieval accuracy, we will explore alternative\n",
        "# embedding models. We'll set up two options: a powerful open-source model\n",
        "# from Hugging Face and a high-performing commercial model from Cohere.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- Step 8: Exploring Alternative Embedding Models ---\")\n",
        "\n",
        "# --- Option 1: Set up for a Hugging Face Model ---\n",
        "# We select 'BAAI/bge-large-en-v1.5' which is a strong open-source model.\n",
        "# The necessary libraries (`sentence-transformers`, `langchain-community`) are already installed.\n",
        "hf_model_name = \"BAAI/bge-large-en-v1.5\"\n",
        "print(f\"Selected Hugging Face model: '{hf_model_name}'\")\n",
        "\n",
        "\n",
        "# --- Option 2: Set up for a Cohere Model ---\n",
        "# We'll use Cohere's 'embed-english-v3.0' model.\n",
        "# First, we need to install the specific LangChain integration for Cohere.\n",
        "print(\"\\nInstalling 'langchain-cohere' for Cohere embeddings...\")\n",
        "!pip install -q langchain-cohere\n",
        "print(\"Installation complete.\")\n",
        "\n",
        "# Next, we need to load the Cohere API key from Colab secrets.\n",
        "try:\n",
        "    os.environ['COHERE_API_KEY'] = userdata.get('COHERE_API_KEY')\n",
        "    print(\"✅ Cohere API Key loaded successfully.\")\n",
        "    cohere_model_name = \"embed-english-v3.0\"\n",
        "    print(f\"Selected Cohere model: '{cohere_model_name}'\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not load Cohere API key. Please set 'COHERE_API_KEY' in Colab's secrets manager. Details: {e}\")\n",
        "\n",
        "print(\"\\nSetup for alternative embedding models is complete. Next step will be to initialize and test them.\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 8: Exploring Alternative Embedding Models ---\n",
            "Selected Hugging Face model: 'BAAI/bge-large-en-v1.5'\n",
            "\n",
            "Installing 'langchain-cohere' for Cohere embeddings...\n",
            "Installation complete.\n",
            "ERROR: Could not load Cohere API key. Please set 'COHERE_API_KEY' in Colab's secrets manager. Details: Secret COHERE_API_KEY does not exist.\n",
            "\n",
            "Setup for alternative embedding models is complete. Next step will be to initialize and test them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6889aef8"
      },
      "source": [
        "**Reasoning**:\n",
        "I have identified two potential alternative embedding models. The next step is to initialize the Hugging Face model as it does not require an external API key that failed to load. I will not initialize the Cohere model due to the missing API key. I will then update the vector store with the new embedding model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20632ef7",
        "outputId": "fe6a586a-962c-4126-e852-ed746594e730"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 8.1: Initialize and Test Alternative Embedding Model (Hugging Face)\n",
        "# ==============================================================================\n",
        "# We will initialize the selected Hugging Face embedding model and update\n",
        "# the Astra DB vector store to use this new model.\n",
        "# ==============================================================================\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "print(\"--- Step 8.1: Initializing and Updating with Hugging Face Embedding Model ---\")\n",
        "\n",
        "# Initialize the Hugging Face embedding model\n",
        "print(f\"Initializing Hugging Face embedding model: '{hf_model_name}'...\")\n",
        "try:\n",
        "    # Use the BGE specific class for better performance and configuration\n",
        "    new_embedding_model = HuggingFaceBgeEmbeddings(model_name=hf_model_name)\n",
        "    print(\"Hugging Face embedding model initialized successfully.\")\n",
        "\n",
        "    # Re-initialize the Astra DB vector store with the new embedding model\n",
        "    print(\"\\nRe-initializing Astra DB vector store with the new embedding model...\")\n",
        "    # ACTION REQUIRED: Choose a NEW name for your collection in Astra DB\n",
        "    # Using a new collection name prevents conflicts with the previous embedding model\n",
        "    new_collection_name = \"my_rag_collection_bge\" # <-- CHANGE THIS to a unique name\n",
        "    print(f\"Using new collection name: '{new_collection_name}'\")\n",
        "\n",
        "\n",
        "    # Ensure the previous vector_store object is not reused if it had issues\n",
        "    vector_store = AstraDBVectorStore(\n",
        "        embedding=new_embedding_model,\n",
        "        collection_name=new_collection_name,\n",
        "        api_endpoint=os.environ['ASTRA_DB_API_ENDPOINT'],\n",
        "        token=os.environ['ASTRA_DB_APPLICATION_TOKEN'],\n",
        "    )\n",
        "    print(f\"Astra DB vector store re-initialized with collection '{new_collection_name}' and the new embedding model.\")\n",
        "\n",
        "    # Add the document chunks to the new vector store\n",
        "    print(\"\\nAdding document chunks to the new Astra DB vector store... (This may take a moment)\")\n",
        "    if 'chunks' in globals() and chunks:\n",
        "        vector_store.add_documents(chunks)\n",
        "        print(f\"{len(chunks)} document chunks added to Astra DB successfully using the new embedding model.\\n\")\n",
        "    else:\n",
        "        print(\"ERROR: 'chunks' variable not found. Cannot add documents to the new vector store.\")\n",
        "\n",
        "    # Update the RAG chain with the new retriever\n",
        "    print(\"Updating the RAG chain with the retriever from the new vector store...\")\n",
        "    retriever = vector_store.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={'k': 5}\n",
        "    )\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    print(\"RAG chain updated successfully with the new embedding model and retriever.\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not initialize or update with the Hugging Face embedding model or update the vector store/chain. Details: {e}\")\n",
        "\n",
        "\n",
        "# Skip Cohere initialization due to missing API key\n",
        "# if 'COHERE_API_KEY' in os.environ and os.environ['COHERE_API_KEY']:\n",
        "#     print(f\"\\nSkipping Cohere model initialization due to missing API key.\")\n",
        "#     # from langchain_cohere import CohereEmbeddings\n",
        "#     # print(f\"Initializing Cohere embedding model: '{cohere_model_name}'...\")\n",
        "#     # cohere_embedding_model = CohereEmbeddings(model=cohere_model_name)\n",
        "#     # print(\"Cohere embedding model initialized successfully.\")\n",
        "# else:\n",
        "#     print(\"\\nSkipping Cohere model initialization because COHERE_API_KEY was not loaded.\")\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 8.1: Initializing and Updating with Hugging Face Embedding Model ---\n",
            "Initializing Hugging Face embedding model: 'BAAI/bge-large-en-v1.5'...\n",
            "ERROR: Could not initialize or update with the Hugging Face embedding model or update the vector store/chain. Details: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b97e48c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to initialize the Hugging Face model failed because the `sentence-transformers` library was not found, despite being listed as installed earlier. The error message suggests reinstalling it. I will add a step to explicitly reinstall `sentence-transformers` and then retry the initialization of the Hugging Face embedding model and the vector store update.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGFD2ORvysOJ",
        "outputId": "494d1343-e40e-4af6-99da-5ee0733347ff"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 8.1 Retry: Install sentence-transformers and Initialize HF Embedding Model\n",
        "# ==============================================================================\n",
        "# The previous attempt to initialize the Hugging Face model failed due to a\n",
        "# missing sentence-transformers dependency. We will reinstall it and retry.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- Step 8.1 Retry: Installing sentence-transformers and Initializing HF Embedding Model ---\")\n",
        "\n",
        "# Reinstall sentence-transformers\n",
        "print(\"Reinstalling 'sentence-transformers'...\")\n",
        "!pip install -q --upgrade sentence-transformers\n",
        "print(\"'sentence-transformers' installation complete.\")\n",
        "\n",
        "# Now, retry initializing the Hugging Face embedding model\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings # Keep the import\n",
        "\n",
        "print(f\"\\nAttempting to re-initialize Hugging Face embedding model: '{hf_model_name}'...\")\n",
        "try:\n",
        "    new_embedding_model = HuggingFaceBgeEmbeddings(model_name=hf_model_name)\n",
        "    print(\"Hugging Face embedding model initialized successfully.\")\n",
        "\n",
        "    # Re-initialize the Astra DB vector store with the new embedding model\n",
        "    print(\"\\nRe-initializing Astra DB vector store with the new embedding model...\")\n",
        "    # Use the previously defined NEW collection name\n",
        "    new_collection_name = \"my_rag_collection_bge\" # Ensure this matches the previous cell\n",
        "\n",
        "    # Ensure the previous vector_store object is not reused if it had issues\n",
        "    vector_store = AstraDBVectorStore(\n",
        "        embedding=new_embedding_model,\n",
        "        collection_name=new_collection_name,\n",
        "        api_endpoint=os.environ['ASTRA_DB_API_ENDPOINT'],\n",
        "        token=os.environ['ASTRA_DB_APPLICATION_TOKEN'],\n",
        "    )\n",
        "    print(f\"Astra DB vector store re-initialized with collection '{new_collection_name}' and the new embedding model.\")\n",
        "\n",
        "    # Add the document chunks to the new vector store\n",
        "    print(\"\\nAdding document chunks to the new Astra DB vector store... (This may take a moment)\")\n",
        "    if 'chunks' in globals() and chunks:\n",
        "        vector_store.add_documents(chunks)\n",
        "        print(f\"{len(chunks)} document chunks added to Astra DB successfully using the new embedding model.\\n\")\n",
        "    else:\n",
        "        print(\"ERROR: 'chunks' variable not found. Cannot add documents to the new vector store.\")\n",
        "\n",
        "    # Update the RAG chain with the new retriever\n",
        "    print(\"Updating the RAG chain with the retriever from the new vector store...\")\n",
        "    retriever = vector_store.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={'k': 5}\n",
        "    )\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    print(\"RAG chain updated successfully with the new embedding model and retriever.\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not initialize or update with the Hugging Face embedding model or update the vector store/chain. Details: {e}\")\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 8.1 Retry: Installing sentence-transformers and Initializing HF Embedding Model ---\n",
            "Reinstalling 'sentence-transformers'...\n",
            "'sentence-transformers' installation complete.\n",
            "\n",
            "Attempting to re-initialize Hugging Face embedding model: 'BAAI/bge-large-en-v1.5'...\n",
            "ERROR: Could not initialize or update with the Hugging Face embedding model or update the vector store/chain. Details: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "738fcf90"
      },
      "source": [
        "**Reasoning**:\n",
        "Despite reinstalling `sentence-transformers`, the initialization of `HuggingFaceBgeEmbeddings` is still failing with the same import error. This suggests there might be an environment issue or a conflict that a simple reinstall isn't resolving. Given the persistent error and the deprecation warning for `HuggingFaceBgeEmbeddings`, I will try a different approach by explicitly installing the recommended `langchain-huggingface` package and using the updated import path as suggested in the deprecation warning. If this still fails, I will have to conclude that there's an unresolvable environment issue preventing the use of this model and report failure for the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dd92711",
        "outputId": "d01e8a8f-30bc-4822-8367-4a83f326585c"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 8.1 Further Retry: Install langchain-huggingface and Initialize HF Embedding Model\n",
        "# ==============================================================================\n",
        "# The previous attempts failed to import sentence-transformers. We will try\n",
        "# installing the recommended 'langchain-huggingface' package and use the\n",
        "# updated import path to see if this resolves the issue.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- Step 8.1 Further Retry: Installing langchain-huggingface and Initializing HF Embedding Model ---\")\n",
        "\n",
        "# Install the recommended langchain-huggingface package\n",
        "print(\"Installing 'langchain-huggingface'...\")\n",
        "!pip install -q -U langchain-huggingface\n",
        "print(\"'langchain-huggingface' installation complete.\")\n",
        "\n",
        "# Now, attempt to initialize the Hugging Face embedding model using the new import path\n",
        "try:\n",
        "    from langchain_huggingface import HuggingFaceEmbeddings # Use the new import\n",
        "\n",
        "    print(f\"\\nAttempting to re-initialize Hugging Face embedding model using new import: '{hf_model_name}'...\")\n",
        "    # The HuggingFaceEmbeddings class from langchain-huggingface should work with the model name\n",
        "    new_embedding_model = HuggingFaceEmbeddings(model_name=hf_model_name)\n",
        "    print(\"Hugging Face embedding model initialized successfully using langchain-huggingface.\")\n",
        "\n",
        "    # Re-initialize the Astra DB vector store with the new embedding model\n",
        "    print(\"\\nRe-initializing Astra DB vector store with the new embedding model...\")\n",
        "    # Use the previously defined NEW collection name\n",
        "    new_collection_name = \"my_rag_collection_bge\" # Ensure this matches the previous cell\n",
        "\n",
        "    # Ensure the previous vector_store object is not reused if it had issues\n",
        "    vector_store = AstraDBVectorStore(\n",
        "        embedding=new_embedding_model,\n",
        "        collection_name=new_collection_name,\n",
        "        api_endpoint=os.environ['ASTRA_DB_API_ENDPOINT'],\n",
        "        token=os.environ['ASTRA_DB_APPLICATION_TOKEN'],\n",
        "    )\n",
        "    print(f\"Astra DB vector store re-initialized with collection '{new_collection_name}' and the new embedding model.\")\n",
        "\n",
        "    # Add the document chunks to the new vector store\n",
        "    print(\"\\nAdding document chunks to the new Astra DB vector store... (This may take a moment)\")\n",
        "    if 'chunks' in globals() and chunks:\n",
        "        vector_store.add_documents(chunks)\n",
        "        print(f\"{len(chunks)} document chunks added to Astra DB successfully using the new embedding model.\\n\")\n",
        "    else:\n",
        "        print(\"ERROR: 'chunks' variable not found. Cannot add documents to the new vector store.\")\n",
        "\n",
        "    # Update the RAG chain with the new retriever\n",
        "    print(\"Updating the RAG chain with the retriever from the new vector store...\")\n",
        "    retriever = vector_store.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={'k': 5}\n",
        "    )\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    print(\"RAG chain updated successfully with the new embedding model and retriever.\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not initialize or update with the Hugging Face embedding model or update the vector store/chain. Details: {e}\")\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 8.1 Further Retry: Installing langchain-huggingface and Initializing HF Embedding Model ---\n",
            "Installing 'langchain-huggingface'...\n",
            "'langchain-huggingface' installation complete.\n",
            "\n",
            "Attempting to re-initialize Hugging Face embedding model using new import: 'BAAI/bge-large-en-v1.5'...\n",
            "ERROR: Could not initialize or update with the Hugging Face embedding model or update the vector store/chain. Details: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eef04db"
      },
      "source": [
        "## Optimize retrieval strategy\n",
        "\n",
        "### Subtask:\n",
        "Explore and implement more advanced retrieval techniques such as:\n",
        "- Different similarity metrics.\n",
        "- Adding metadata filtering based on document properties.\n",
        "- Implementing hybrid search (combining vector search with keyword search).\n",
        "- Exploring re-ranking of retrieved documents to improve precision.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90100fd3"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import necessary classes for hybrid search and re-ranking and then implement one or more advanced retrieval techniques. I will start by implementing hybrid search by combining the existing vector store retriever with a keyword-based retriever. This requires importing `BM25Retriever` and `EnsembleRetriever`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c93407b2",
        "outputId": "cd56d7db-7326-4d0e-8d05-f68948e66082"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 9: EXPLORE AND IMPLEMENT ADVANCED RETRIEVAL TECHNIQUES\n",
        "# ==============================================================================\n",
        "# We will implement hybrid search by combining vector search (using our Astra DB\n",
        "# vector store) with keyword search (using BM25). This can improve retrieval\n",
        "# by capturing both semantic similarity and keyword relevance.\n",
        "# ==============================================================================\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "print(\"--- Step 9: Exploring and Implementing Advanced Retrieval Techniques (Hybrid Search) ---\")\n",
        "\n",
        "# 1. Create a keyword-based retriever (BM25)\n",
        "# We need to create a BM25 retriever from the document chunks.\n",
        "print(\"Creating BM25 keyword retriever...\")\n",
        "# Ensure 'chunks' variable is available from a previous cell's execution\n",
        "if 'chunks' in globals() and chunks:\n",
        "    keyword_retriever = BM25Retriever.from_documents(chunks)\n",
        "    keyword_retriever.k = 5 # Set the number of documents to retrieve for BM25\n",
        "    print(f\"BM25 keyword retriever created, set to retrieve {keyword_retriever.k} documents.\")\n",
        "else:\n",
        "    print(\"ERROR: 'chunks' variable not found. Cannot create BM25 retriever.\")\n",
        "    keyword_retriever = None # Set to None if chunks are not available\n",
        "\n",
        "\n",
        "# 2. Configure the vector store retriever\n",
        "# We already have the Astra DB vector store retriever configured for MMR in Step 6.1.\n",
        "# We'll ensure it also retrieves a similar number of documents for the ensemble.\n",
        "if 'vector_store' in globals():\n",
        "    vector_retriever = vector_store.as_retriever(\n",
        "        search_type=\"mmr\", # Use Maximal Marginal Relevance for retrieval\n",
        "        search_kwargs={'k': 5} # Fetch the top 5 most relevant documents\n",
        "    )\n",
        "    print(f\"Vector store retriever configured, set to retrieve {vector_retriever.search_kwargs['k']} documents.\")\n",
        "else:\n",
        "    print(\"ERROR: 'vector_store' variable not found. Cannot configure vector retriever.\")\n",
        "    vector_retriever = None\n",
        "\n",
        "\n",
        "# 3. Combine the retrievers using EnsembleRetriever\n",
        "if keyword_retriever and vector_retriever:\n",
        "    print(\"\\nCombining BM25 and Vector retrievers using EnsembleRetriever...\")\n",
        "    # The weights parameter determines the relative importance of each retriever.\n",
        "    # [0.5, 0.5] gives equal weight to both. You can adjust these based on testing.\n",
        "    ensemble_retriever = EnsembleRetriever(\n",
        "        retrievers=[keyword_retriever, vector_retriever],\n",
        "        weights=[0.5, 0.5]\n",
        "    )\n",
        "    print(\"Ensemble (Hybrid) retriever created successfully.\")\n",
        "\n",
        "    # Update the RAG chain to use the new ensemble retriever\n",
        "    print(\"Updating the RAG chain with the new ensemble retriever...\")\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=ensemble_retriever, # Use the ensemble retriever\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    print(\"RAG chain updated successfully with the hybrid retrieval strategy.\\n\")\n",
        "else:\n",
        "    print(\"ERROR: Could not create both keyword and vector retrievers. Skipping EnsembleRetriever setup.\")\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 9: Exploring and Implementing Advanced Retrieval Techniques (Hybrid Search) ---\n",
            "Creating BM25 keyword retriever...\n",
            "BM25 keyword retriever created, set to retrieve 5 documents.\n",
            "Vector store retriever configured, set to retrieve 5 documents.\n",
            "\n",
            "Combining BM25 and Vector retrievers using EnsembleRetriever...\n",
            "Ensemble (Hybrid) retriever created successfully.\n",
            "Updating the RAG chain with the new ensemble retriever...\n",
            "RAG chain updated successfully with the hybrid retrieval strategy.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8221c24"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `rank_bm25` library is not installed. I need to install this library to use the `BM25Retriever`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyR1MyBty4mX",
        "outputId": "1cff8358-e404-4367-bd29-cc39cd5045e4"
      },
      "source": [
        "# Install the rank_bm25 library\n",
        "print(\"Installing 'rank_bm25'...\")\n",
        "!pip install -q rank_bm25\n",
        "print(\"'rank_bm25' installation complete.\")\n",
        "\n",
        "# Now, retry the previous step to create the hybrid retriever\n",
        "print(\"\\n--- Step 9: Exploring and Implementing Advanced Retrieval Techniques (Hybrid Search) ---\")\n",
        "\n",
        "# 1. Create a keyword-based retriever (BM25)\n",
        "# We need to create a BM25 retriever from the document chunks.\n",
        "print(\"Creating BM25 keyword retriever...\")\n",
        "# Ensure 'chunks' variable is available from a previous cell's execution\n",
        "if 'chunks' in globals() and chunks:\n",
        "    keyword_retriever = BM25Retriever.from_documents(chunks)\n",
        "    keyword_retriever.k = 5 # Set the number of documents to retrieve for BM25\n",
        "    print(f\"BM25 keyword retriever created, set to retrieve {keyword_retriever.k} documents.\")\n",
        "else:\n",
        "    print(\"ERROR: 'chunks' variable not found. Cannot create BM25 retriever.\")\n",
        "    keyword_retriever = None # Set to None if chunks are not available\n",
        "\n",
        "\n",
        "# 2. Configure the vector store retriever\n",
        "# We already have the Astra DB vector store retriever configured for MMR in Step 6.1.\n",
        "# We'll ensure it also retrieves a similar number of documents for the ensemble.\n",
        "if 'vector_store' in globals():\n",
        "    vector_retriever = vector_store.as_retriever(\n",
        "        search_type=\"mmr\", # Use Maximal Marginal Relevance for retrieval\n",
        "        search_kwargs={'k': 5} # Fetch the top 5 most relevant documents\n",
        "    )\n",
        "    print(f\"Vector store retriever configured, set to retrieve {vector_retriever.search_kwargs['k']} documents.\")\n",
        "else:\n",
        "    print(\"ERROR: 'vector_store' variable not found. Cannot configure vector retriever.\")\n",
        "    vector_retriever = None\n",
        "\n",
        "\n",
        "# 3. Combine the retrievers using EnsembleRetriever\n",
        "if keyword_retriever and vector_retriever:\n",
        "    print(\"\\nCombining BM25 and Vector retrievers using EnsembleRetriever...\")\n",
        "    # The weights parameter determines the relative importance of each retriever.\n",
        "    # [0.5, 0.5] gives equal weight to both. You can adjust these based on testing.\n",
        "    ensemble_retriever = EnsembleRetriever(\n",
        "        retrievers=[keyword_retriever, vector_retriever],\n",
        "        weights=[0.5, 0.5]\n",
        "    )\n",
        "    print(\"Ensemble (Hybrid) retriever created successfully.\")\n",
        "\n",
        "    # Update the RAG chain to use the new ensemble retriever\n",
        "    print(\"Updating the RAG chain with the new ensemble retriever...\")\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=ensemble_retriever, # Use the ensemble retriever\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    print(\"RAG chain updated successfully with the hybrid retrieval strategy.\\n\")\n",
        "else:\n",
        "    print(\"ERROR: Could not create both keyword and vector retrievers. Skipping EnsembleRetriever setup.\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing 'rank_bm25'...\n",
            "'rank_bm25' installation complete.\n",
            "\n",
            "--- Step 9: Exploring and Implementing Advanced Retrieval Techniques (Hybrid Search) ---\n",
            "Creating BM25 keyword retriever...\n",
            "BM25 keyword retriever created, set to retrieve 5 documents.\n",
            "Vector store retriever configured, set to retrieve 5 documents.\n",
            "\n",
            "Combining BM25 and Vector retrievers using EnsembleRetriever...\n",
            "Ensemble (Hybrid) retriever created successfully.\n",
            "Updating the RAG chain with the new ensemble retriever...\n",
            "RAG chain updated successfully with the hybrid retrieval strategy.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9458fc7"
      },
      "source": [
        "## Enhance prompt engineering\n",
        "\n",
        "### Subtask:\n",
        "Refine the prompt template used with the LLM to guide it towards generating more accurate and concise answers based on the retrieved context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e31fe45c"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the prompt template to be more specific about how the LLM should use the context and format the output, then update the RAG chain with the refined prompt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da4ce92e",
        "outputId": "b861602c-b4ff-4249-be72-03883235d53e"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7.1: Refine the Prompt Template\n",
        "# ==============================================================================\n",
        "# We will update the prompt template to provide clearer instructions to the LLM\n",
        "# on how to utilize the context for generating accurate and user-friendly answers.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- Step 7.1: Refining the Prompt Template ---\")\n",
        "\n",
        "# Refine the prompt template\n",
        "prompt_template = \"\"\"\n",
        "INSTRUCTIONS:\n",
        "You are a helpful assistant specializing in analyzing insurance policy documents.\n",
        "Your task is to answer the user's question based *strictly* on the CONTEXT provided below.\n",
        "Read the CONTEXT carefully. The CONTEXT consists of multiple document snippets.\n",
        "Synthesize information from ALL relevant snippets in the CONTEXT to provide a concise and accurate answer.\n",
        "If the answer is found, present it clearly and directly in a simple, easy-to-understand format, avoiding jargon where possible.\n",
        "If the CONTEXT does NOT contain the information needed to answer the question, you MUST respond with: \"I do not have enough information in the provided document to answer this question.\"\n",
        "Do NOT make up information or use any external knowledge. Do NOT refer to the source documents or page numbers in your answer.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\"\n",
        "\n",
        "# Update the PROMPT variable with the refined template\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "print(\"Prompt template refined and updated.\")\n",
        "\n",
        "# Re-create the RetrievalQA chain with the updated PROMPT\n",
        "print(\"Re-building the RAG chain with the refined prompt...\")\n",
        "# Ensure llm and retriever variables are available from previous steps\n",
        "if 'llm' in globals() and 'retriever' in globals():\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True, # Keep this to see which docs were retrieved\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    print(\"RAG chain updated successfully with the refined prompt.\\n\")\n",
        "else:\n",
        "    print(\"ERROR: 'llm' or 'retriever' variables not found. Cannot rebuild the RAG chain.\")\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7.1: Refining the Prompt Template ---\n",
            "Prompt template refined and updated.\n",
            "Re-building the RAG chain with the refined prompt...\n",
            "RAG chain updated successfully with the refined prompt.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62605cdc"
      },
      "source": [
        "## Evaluate and potentially change llm\n",
        "\n",
        "### Subtask:\n",
        "Consider if a different LLM might be better suited for synthesizing answers from the retrieved context and generating user-friendly responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c6c76ab"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import a different LLM from `langchain_google_genai`, initialize it, and update the `qa_chain` to use this new LLM. I will choose 'gemini-1.5-pro-latest' as it is generally considered more capable than 'gemini-1.5-flash-latest'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50b64aa7",
        "outputId": "d9c2cadd-9a10-4b3d-bd0e-9c15bbfdc777"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 10: Consider Alternative LLMs\n",
        "# ==============================================================================\n",
        "# We will explore using a potentially more capable LLM from Google's Gemini family\n",
        "# to see if it improves the quality of synthesized answers.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- Step 10: Considering Alternative LLMs ---\")\n",
        "\n",
        "# 1. Import a different LLM class (already imported GoogleGenerativeAI)\n",
        "# 2. Initialize the new LLM.\n",
        "# We will use 'gemini-1.5-pro-latest' as it is generally more capable.\n",
        "print(\"Initializing a new LLM: 'gemini-1.5-pro-latest'...\")\n",
        "try:\n",
        "    # Ensure the previous llm variable is not causing conflicts, though reassigning is fine.\n",
        "    new_llm = GoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", temperature=0.7)\n",
        "    print(\"New LLM (gemini-1.5-pro-latest) initialized successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not initialize the new LLM. Details: {e}\")\n",
        "    new_llm = None # Set to None if initialization fails\n",
        "\n",
        "# 3. Update the qa_chain variable to use the newly initialized LLM\n",
        "if new_llm and 'retriever' in globals() and 'PROMPT' in globals():\n",
        "    print(\"Updating the RAG chain to use the new LLM...\")\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=new_llm,  # Use the new LLM\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever, # Keep the previously configured retriever\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT} # Keep the refined prompt\n",
        "    )\n",
        "    print(\"RAG chain updated successfully with the new LLM.\\n\")\n",
        "else:\n",
        "    print(\"ERROR: Could not update the RAG chain. Ensure new_llm, retriever, and PROMPT are available.\")\n",
        "\n",
        "# 4. Print a confirmation message and rationale\n",
        "if new_llm:\n",
        "    print(\"LLM has been changed to 'gemini-1.5-pro-latest' and the RAG chain updated.\")\n",
        "    print(\"Rationale: 'gemini-1.5-pro-latest' is chosen for its potentially stronger reasoning and synthesis capabilities compared to 'gemini-1.5-flash-latest', which might lead to more accurate and nuanced answers from the retrieved context.\")\n",
        "else:\n",
        "    print(\"LLM change and RAG chain update failed due to LLM initialization error.\")\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 10: Considering Alternative LLMs ---\n",
            "Initializing a new LLM: 'gemini-1.5-pro-latest'...\n",
            "New LLM (gemini-1.5-pro-latest) initialized successfully.\n",
            "Updating the RAG chain to use the new LLM...\n",
            "RAG chain updated successfully with the new LLM.\n",
            "\n",
            "LLM has been changed to 'gemini-1.5-pro-latest' and the RAG chain updated.\n",
            "Rationale: 'gemini-1.5-pro-latest' is chosen for its potentially stronger reasoning and synthesis capabilities compared to 'gemini-1.5-flash-latest', which might lead to more accurate and nuanced answers from the retrieved context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c1f26a6"
      },
      "source": [
        "## Improve output formatting\n",
        "\n",
        "### Subtask:\n",
        "Modify the final output presentation to be clearer and more easily understandable for a normal user, potentially using markdown formatting or structuring the answer differently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceaf272e"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the interactive question answering code to improve the output formatting for better readability and user understanding, displaying multiple source documents if available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9c80048f",
        "outputId": "66df6dd5-0f40-4275-c9da-a37614b22b53"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: ASK A QUESTION INTERACTIVELY (Improved Output Formatting)\n",
        "# ==============================================================================\n",
        "# Now that the RAG chain is set up, we can ask questions about the documents.\n",
        "# The chain will retrieve relevant information and use the LLM to generate\n",
        "# an answer based on the retrieved context.\n",
        "# This version allows you to input your question directly and presents the\n",
        "# answer and source documents in a more user-friendly format using markdown.\n",
        "# ==============================================================================\n",
        "print(\"--- Step 7: Asking a Question Interactively (Improved Output) ---\")\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Invoke the RAG chain with your query\n",
        "response = qa_chain.invoke(query)\n",
        "\n",
        "# Print the answer with clear markdown formatting\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"✨ **ANSWER** ✨\")\n",
        "print(\"=\"*40)\n",
        "print(response['result'])\n",
        "\n",
        "# Display source documents with clear markdown formatting\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"📚 **SOURCE DOCUMENTS** 📚\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "if response['source_documents']:\n",
        "    for i, doc in enumerate(response['source_documents']):\n",
        "        print(f\"\\n--- **Document {i+1}** ---\")\n",
        "        print(f\"  **Source:** {doc.metadata.get('source', 'N/A')}\")\n",
        "        print(f\"  **Page:** {doc.metadata.get('page', 'N/A')}\")\n",
        "        # Display a content snippet, limiting length for clarity\n",
        "        content_snippet = doc.page_content\n",
        "        if len(content_snippet) > 500:\n",
        "            content_snippet = content_snippet[:500] + \"...\"\n",
        "        print(f\"  **Content Snippet:**\\n```\\n{content_snippet}\\n```\") # Use markdown code block for snippet\n",
        "        print(\"-\" * 30)\n",
        "    print(\"\\n*Note: The answer may have been synthesized from multiple source documents, but only the most relevant are shown here.*\")\n",
        "else:\n",
        "    print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "print(\"\\nTask completed. You can now run the cell again to ask another question.\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Step 7: Asking a Question Interactively (Improved Output) ---\n",
            "Please enter your question about the documents: A 35-year-old individual needs in-patient treatment for severe depression. Does the Global Health Care policy cover hospitalization for mental illness?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 51\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 49\n}\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-492083195.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Invoke the RAG chain with your query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Print the answer with clear markdown formatting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         answer = self.combine_documents_chain.run(\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    633\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# Call predict on the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     async def acombine_docs(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> dict[str, str]:\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    765\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 )\n\u001b[1;32m    970\u001b[0m             ]\n\u001b[0;32m--> 971\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m    972\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             output = (\n\u001b[0;32m--> 792\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             chat_result = self.client._generate(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         )\n\u001b[0;32m-> 1441\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     )\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             ) from e\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     params = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    869\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 49\n}\n]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab80ce06"
      },
      "source": [
        "## Handle out-of-scope queries\n",
        "\n",
        "### Subtask:\n",
        "Investigate methods to detect when a user's query is outside the scope of the document content and prevent retrieval or provide a specific \"out-of-scope\" response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fbd562a"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to implement a method to detect out-of-scope queries. A simple approach is to check if the retrieved documents are relevant to the query by examining their content or metadata. If the retrieved documents are consistently irrelevant based on some criteria (e.g., low similarity scores, lack of keywords from the query), I can flag the query as out-of-scope. Since the current retriever doesn't provide confidence scores directly in the response, I will implement a basic check by looking for keywords from the query in the content of the retrieved documents. If none of the retrieved documents contain a significant number of keywords from the query, I will consider it out-of-scope.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53d03a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84325f0f-45e0-4f40-d99d-a1b05ee31895"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 11: IMPLEMENT OUT-OF-SCOPE QUERY DETECTION\n",
        "# ==============================================================================\n",
        "# We will add a check before invoking the LLM to see if the retrieved documents\n",
        "# appear relevant to the query. If not, we will provide an out-of-scope message.\n",
        "# ==============================================================================\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "print(\"--- Step 11: Implementing Out-of-Scope Query Detection ---\")\n",
        "\n",
        "# Define a threshold for keyword matching to consider documents relevant\n",
        "KEYWORD_MATCH_THRESHOLD = 2 # Minimum number of query keywords found in retrieved docs\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Retrieve documents first\n",
        "print(\"Retrieving documents for the query...\")\n",
        "retrieved_docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "# Simple check for relevance based on keywords\n",
        "print(\"Checking retrieved documents for relevance...\")\n",
        "query_keywords = set(re.findall(r'\\b\\w+\\b', query.lower())) # Extract keywords from query\n",
        "matched_keywords_count = 0\n",
        "\n",
        "if retrieved_docs:\n",
        "    for doc in retrieved_docs:\n",
        "        doc_content = doc.page_content.lower()\n",
        "        # Count how many query keywords appear in the document content\n",
        "        matched_keywords_count += sum(keyword in doc_content for keyword in query_keywords)\n",
        "\n",
        "    print(f\"Found {matched_keywords_count} keyword matches in retrieved documents.\")\n",
        "\n",
        "    # Determine if the query is likely out of scope\n",
        "    if matched_keywords_count < KEYWORD_MATCH_THRESHOLD:\n",
        "        print(\"\\n\" + \"=\"*30)\n",
        "        print(\"⚠️ OUT OF SCOPE ⚠️\")\n",
        "        print(\"=\"*30)\n",
        "        print(\"I do not have enough information in the provided document to answer this question.\")\n",
        "        print(\"\\nTask completed. Please analyze the output and re-run the cell to ask another question.\")\n",
        "    else:\n",
        "        # If deemed in scope, invoke the RAG chain\n",
        "        print(\"Documents appear relevant. Invoking RAG chain...\")\n",
        "        response = qa_chain.invoke(query)\n",
        "\n",
        "        # Print the answer with clear markdown formatting\n",
        "        print(\"\\n\" + \"=\"*40)\n",
        "        print(\"✨ **ANSWER** ✨\")\n",
        "        print(\"=\"*40)\n",
        "        print(response['result'])\n",
        "\n",
        "        # Display source documents with clear markdown formatting\n",
        "        print(\"\\n\" + \"=\"*40)\n",
        "        print(\"📚 **SOURCE DOCUMENTS** 📚\")\n",
        "        print(\"=\"*40)\n",
        "\n",
        "        if response['source_documents']:\n",
        "            for i, doc in enumerate(response['source_documents']):\n",
        "                print(f\"\\n--- **Document {i+1}** ---\")\n",
        "                print(f\"  **Source:** {doc.metadata.get('source', 'N/A')}\")\n",
        "                print(f\"  **Page:** {doc.metadata.get('page', 'N/A')}\")\n",
        "                # Display a content snippet, limiting length for clarity\n",
        "                content_snippet = doc.page_content\n",
        "                if len(content_snippet) > 500:\n",
        "                    content_snippet = content_snippet[:500] + \"...\"\n",
        "                print(f\"  **Content Snippet:**\\n```\\n{content_snippet}\\n```\") # Use markdown code block for snippet\n",
        "                print(\"-\" * 30)\n",
        "            print(\"\\n*Note: The answer may have been synthesized from multiple source documents, but only the most relevant are shown here.*\")\n",
        "        else:\n",
        "            print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "        print(\"\\nTask completed. You can now run the cell again to ask another question.\")\n",
        "\n",
        "else:\n",
        "    # No documents retrieved at all\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(\"⚠️ OUT OF SCOPE ⚠️\")\n",
        "    print(\"=\"*30)\n",
        "    print(\"No relevant documents were retrieved for this query.\")\n",
        "    print(\"\\nTask completed. Please analyze the output and re-run the cell to ask another question.\")\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 11: Implementing Out-of-Scope Query Detection ---\n",
            "Please enter your question about the documents: A 35-year-old individual needs in-patient treatment for severe depression. Does the Global Health Care policy cover hospitalization for mental illness?\n",
            "Retrieving documents for the query...\n",
            "Checking retrieved documents for relevance...\n",
            "Found 53 keyword matches in retrieved documents.\n",
            "Documents appear relevant. Invoking RAG chain...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 29\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 26\n}\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3681539103.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# If deemed in scope, invoke the RAG chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Documents appear relevant. Invoking RAG chain...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Print the answer with clear markdown formatting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         answer = self.combine_documents_chain.run(\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    633\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# Call predict on the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     async def acombine_docs(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> dict[str, str]:\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    765\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 )\n\u001b[1;32m    970\u001b[0m             ]\n\u001b[0;32m--> 971\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m    972\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             output = (\n\u001b[0;32m--> 792\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             chat_result = self.client._generate(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         )\n\u001b[0;32m-> 1441\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     )\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             ) from e\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     params = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    869\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 26\n}\n]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faa11481"
      },
      "source": [
        "## Evaluate and iterate\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the current performance of the RAG system with the improved chunking, retrieval, and prompt. Test with a variety of questions and analyze the answers and source documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ee7995"
      },
      "source": [
        "**Reasoning**:\n",
        "Run the interactive question answering cell to evaluate the RAG system's performance with the updated chain using the new LLM and hybrid retriever. I will ask a variety of questions and manually analyze the output, focusing on the answers and the retrieved source documents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e8db9815",
        "outputId": "8b17a412-6984-4126-8f38-e91d7542cb82"
      },
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: ASK A QUESTION INTERACTIVELY (Evaluation Run with New LLM/Retriever)\n",
        "# ==============================================================================\n",
        "# Running the interactive question answering cell as instructed for evaluation.\n",
        "# I will ask a variety of questions and manually analyze the output.\n",
        "# This version uses the updated RAG chain with the new LLM and hybrid retriever.\n",
        "# ==============================================================================\n",
        "import re # Ensure re is imported if needed for any potential pre-processing, though not strictly for this core step.\n",
        "\n",
        "print(\"--- Step 7: Asking a Question Interactively (Evaluation Run with New LLM/Retriever) ---\")\n",
        "\n",
        "# Get the question from user input\n",
        "query = input(\"Please enter your question about the documents: \")\n",
        "\n",
        "# Invoke the RAG chain with your query\n",
        "# Ensure qa_chain is available and updated from previous steps (using new LLM and hybrid retriever)\n",
        "if 'qa_chain' in globals():\n",
        "    response = qa_chain.invoke(query)\n",
        "\n",
        "    # Print the answer with clear markdown formatting\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"✨ **ANSWER** ✨\")\n",
        "    print(\"=\"*40)\n",
        "    print(response['result'])\n",
        "\n",
        "    # Display source documents with clear markdown formatting\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"📚 **SOURCE DOCUMENTS** 📚\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    if response['source_documents']:\n",
        "        for i, doc in enumerate(response['source_documents']):\n",
        "            print(f\"\\n--- **Document {i+1}** ---\")\n",
        "            print(f\"  **Source:** {doc.metadata.get('source', 'N/A')}\")\n",
        "            print(f\"  **Page:** {doc.metadata.get('page', 'N/A')}\")\n",
        "            # Display a content snippet, limiting length for clarity\n",
        "            content_snippet = doc.page_content\n",
        "            if len(content_snippet) > 500:\n",
        "                content_snippet = content_snippet[:500] + \"...\"\n",
        "            print(f\"  **Content Snippet:**\\n```\\n{content_snippet}\\n```\") # Use markdown code block for snippet\n",
        "            print(\"-\" * 30)\n",
        "        print(\"\\n*Note: The answer may have been synthesized from multiple source documents, but only the most relevant are shown here.*\")\n",
        "    else:\n",
        "        print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "    print(\"\\nTask completed. Please analyze the output and re-run the cell to ask another question.\")\n",
        "else:\n",
        "    print(\"ERROR: 'qa_chain' variable not found. Please ensure the RAG chain was built successfully in previous steps.\")\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Step 7: Asking a Question Interactively (Evaluation Run with New LLM/Retriever) ---\n",
            "Please enter your question about the documents: A 35-year-old individual needs in-patient treatment for severe depression. Does the Global Health Care policy cover hospitalization for mental illness?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 19\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 17\n}\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3413218358.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Ensure qa_chain is available and updated from previous steps (using new LLM and hybrid retriever)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'qa_chain'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Print the answer with clear markdown formatting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         answer = self.combine_documents_chain.run(\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    633\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# Call predict on the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     async def acombine_docs(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> dict[str, str]:\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    765\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 )\n\u001b[1;32m    970\u001b[0m             ]\n\u001b[0;32m--> 971\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m    972\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             output = (\n\u001b[0;32m--> 792\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             chat_result = self.client._generate(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         )\n\u001b[0;32m-> 1441\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     )\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             ) from e\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     params = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    869\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 17\n}\n]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d74b54a5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Setting up alternative embedding models (Hugging Face and Cohere) failed due to a persistent import error for `sentence-transformers` and a missing Cohere API key.\n",
        "*   Implementing hybrid search using BM25 and vector retrieval was successful after installing the `rank_bm25` library.\n",
        "*   Implementing re-ranking using `SentenceTransformerRerank` failed due to persistent `ImportError`s, as the class could not be found in the expected LangChain locations.\n",
        "*   The prompt template was successfully refined to provide clearer instructions to the LLM for generating answers based on the context.\n",
        "*   The RAG chain was successfully updated to use the 'gemini-1.5-pro-latest' LLM.\n",
        "*   Attempts to evaluate the updated RAG system and test the out-of-scope query detection were hindered by a `ResourceExhausted` error from the Google Generative AI API, preventing the LLM from processing queries.\n",
        "*   A basic keyword-based out-of-scope detection method was implemented but incorrectly flagged an out-of-scope query as \"in scope\" during testing.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Address the `ResourceExhausted` API error to enable further testing and evaluation of the RAG system improvements, including the updated LLM, hybrid retrieval, and prompt engineering.\n",
        "*   Investigate the correct method for implementing re-ranking in the current LangChain version to resolve the `ImportError` and integrate re-ranking into the retrieval strategy.\n",
        "*   Refine the out-of-scope query detection mechanism, as the simple keyword matching proved insufficient; explore more sophisticated methods like semantic similarity checks or using a separate classification model.\n"
      ]
    }
  ]
}